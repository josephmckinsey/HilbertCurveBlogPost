{"99":
 "<code class=\"docstring\">* `unfold id` unfolds all occurrences of definition `id` in the target.\n* `unfold id1 id2 ...` is equivalent to `unfold id1; unfold id2; ...`.\n* `unfold id at h` unfolds at the hypothesis `h`.\n\nDefinitions can be either global or local definitions.\n\nFor non-recursive global definitions, this tactic is identical to `delta`.\nFor recursive global definitions, it uses the \"unfolding lemma\" `id.eq_def`,\nwhich is generated for each recursive definition, to unfold according to the recursive definition given by the user.\nOnly one level of unfolding is performed, in contrast to `simp only [id]`, which unfolds definition `id` recursively.\n</code>",
 "98": "<code>get_quadrant' i (hilbert_curve (i + 1) n) = q</code>",
 "97": "<code>HilbertCurve.Quadrant : Type</code>",
 "96": "<code>q = get_quadrant i n</code>",
 "95": "<code>Quadrant</code>",
 "94":
 "<code>get_quadrant' i (hilbert_curve (i + 1) n) = get_quadrant i n</code>",
 "93": "<code>n &lt; hilbert_length (i + 1)</code>",
 "92":
 "<code>‚àÄ n &lt; hilbert_length i, hilbert_inverse i (hilbert_curve i n) = n</code>",
 "91": "<code>n = 0</code>",
 "90": "<code>n &lt; hilbert_length 0</code>",
 "9": "<code>Type u_1</code>",
 "89":
 "<code class=\"docstring\">Location specifications are used by many tactics that can operate on either the\nhypotheses or the goal. It can have one of the forms:\n* 'empty' is not actually present in this syntax, but most tactics use\n  `(location)?` matchers. It means to target the goal only.\n* `at h‚ÇÅ ... h‚Çô`: target the hypotheses `h‚ÇÅ`, ..., `h‚Çô`\n* `at h‚ÇÅ h‚ÇÇ ‚ä¢`: target the hypotheses `h‚ÇÅ` and `h‚ÇÇ`, and the goal\n* `at *`: target all hypotheses and the goal\n</code>",
 "88":
 "<code class=\"docstring\">After `with`, there is an optional tactic that runs on all branches, and\nthen a list of alternatives.\n</code>",
 "87":
 "<code class=\"docstring\">Assuming `x` is a variable in the local context with an inductive type,\n`induction x` applies induction on `x` to the main goal,\nproducing one goal for each constructor of the inductive type,\nin which the target is replaced by a general instance of that constructor\nand an inductive hypothesis is added for each recursive argument to the constructor.\nIf the type of an element in the local context depends on `x`,\nthat element is reverted and reintroduced afterward,\nso that the inductive hypothesis incorporates that hypothesis as well.\n\nFor example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,\n`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,\nand one goal with hypotheses `h : P (Nat.succ a)` and `ih‚ÇÅ : P a ‚Üí Q a` and target `Q (Nat.succ a)`.\nHere the names `a` and `ih‚ÇÅ` are chosen automatically and are not accessible.\nYou can use `with` to provide the variables names for each constructor.\n- `induction e`, where `e` is an expression instead of a variable,\n  generalizes `e` in the goal, and then performs induction on the resulting variable.\n- `induction e using r` allows the user to specify the principle of induction that should be used.\n  Here `r` should be a term whose result type must be of the form `C t`,\n  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables\n- `induction e generalizing z‚ÇÅ ... z‚Çô`, where `z‚ÇÅ ... z‚Çô` are variables in the local context,\n  generalizes over `z‚ÇÅ ... z‚Çô` before applying the induction but then introduces them in each goal.\n  In other words, the net effect is that each inductive hypothesis is generalized.\n- Given `x : Nat`, `induction x with | zero =&gt; tac‚ÇÅ | succ x' ih =&gt; tac‚ÇÇ`\n  uses tactic `tac‚ÇÅ` for the `zero` case, and `tac‚ÇÇ` for the `succ` case.\n</code>",
 "86": "<code>HilbertCurve.hilbert_inverse : ‚Ñï ‚Üí ‚Ñï √ó ‚Ñï ‚Üí ‚Ñï</code>",
 "85": "<code>HilbertCurve.hilbert_length (i : ‚Ñï) : ‚Ñï</code>",
 "84": "<code>n &lt; hilbert_length i</code>",
 "83":
 "<code>HilbertCurve.hilbert_curve_injective (i n : ‚Ñï) (h : n &lt; hilbert_length i) : hilbert_inverse i (hilbert_curve i n) = n</code><span class=\"sep\"></span><code class=\"docstring\">A hilbert curve is injective on its length\n</code>",
 "82":
 "<code class=\"docstring\">The `sorry` tactic is a temporary placeholder for an incomplete tactic proof,\nclosing the main goal using `exact sorry`.\n\nThis is intended for stubbing-out incomplete parts of a proof while still having a syntactically correct proof skeleton.\nLean will give a warning whenever a proof uses `sorry`, so you aren't likely to miss it,\nbut you can double check if a theorem depends on `sorry` by looking for `sorryAx` in the output\nof the `#print axioms my_thm` command, the axiom used by the implementation of `sorry`.\n</code>",
 "81": "<code>HilbertCurve.get_quadrant (i n : ‚Ñï) : Quadrant</code>",
 "80": "<code>HilbertCurve.hilbert_curve : ‚Ñï ‚Üí ‚Ñï ‚Üí ‚Ñï √ó ‚Ñï</code>",
 "8":
 "<code class=\"docstring\">Declares one or more typed variables, or modifies whether already-declared variables are\n  implicit.\n\nIntroduces variables that can be used in definitions within the same `namespace` or `section` block.\nWhen a definition mentions a variable, Lean will add it as an argument of the definition. This is\nuseful in particular when writing many definitions that have parameters in common (see below for an\nexample).\n\nVariable declarations have the same flexibility as regular function parameters. In particular they\ncan be [explicit, implicit][binder docs], or [instance implicit][tpil classes] (in which case they\ncan be anonymous). This can be changed, for instance one can turn explicit variable `x` into an\nimplicit one with `variable {x}`. Note that currently, you should avoid changing how variables are\nbound and declare new variables at the same time; see [issue 2789] for more on this topic.\n\nIn *theorem bodies* (i.e. proofs), variables are not included based on usage in order to ensure that\nchanges to the proof cannot change the statement of the overall theorem. Instead, variables are only\navailable to the proof if they have been mentioned in the theorem header or in an `include` command\nor are instance implicit and depend only on such variables.\n\nSee [*Variables and Sections* from Theorem Proving in Lean][tpil vars] for a more detailed\ndiscussion.\n\n[tpil vars]:\nhttps://lean-lang.org/theorem_proving_in_lean4/dependent_type_theory.html#variables-and-sections\n(Variables and Sections on Theorem Proving in Lean) [tpil classes]:\nhttps://lean-lang.org/theorem_proving_in_lean4/type_classes.html (Type classes on Theorem Proving in\nLean) [binder docs]:\nhttps://leanprover-community.github.io/mathlib4_docs/Lean/Expr.html#Lean.BinderInfo (Documentation\nfor the BinderInfo type) [issue 2789]: https://github.com/leanprover/lean4/issues/2789 (Issue 2789\non github)\n\n## Examples\n\n```lean\nsection\n  variable\n    {Œ± : Type u}      -- implicit\n    (a : Œ±)           -- explicit\n    [instBEq : BEq Œ±] -- instance implicit, named\n    [Hashable Œ±]      -- instance implicit, anonymous\n\n  def isEqual (b : Œ±) : Bool :=\n    a == b\n\n  #check isEqual\n  -- isEqual.{u} {Œ± : Type u} (a : Œ±) [instBEq : BEq Œ±] (b : Œ±) : Bool\n\n  variable\n    {a} -- `a` is implicit now\n\n  def eqComm {b : Œ±} := a == b ‚Üî b == a\n\n  #check eqComm\n  -- eqComm.{u} {Œ± : Type u} {a : Œ±} [instBEq : BEq Œ±] {b : Œ±} : Prop\nend\n```\n\nThe following shows a typical use of `variable` to factor out definition arguments:\n\n```lean\nvariable (Src : Type)\n\nstructure Logger where\n  trace : List (Src √ó String)\n#check Logger\n-- Logger (Src : Type) : Type\n\nnamespace Logger\n  -- switch `Src : Type` to be implicit until the `end Logger`\n  variable {Src}\n\n  def empty : Logger Src where\n    trace := []\n  #check empty\n  -- Logger.empty {Src : Type} : Logger Src\n\n  variable (log : Logger Src)\n\n  def len :=\n    log.trace.length\n  #check len\n  -- Logger.len {Src : Type} (log : Logger Src) : Nat\n\n  variable (src : Src) [BEq Src]\n\n  -- at this point all of `log`, `src`, `Src` and the `BEq` instance can all become arguments\n\n  def filterSrc :=\n    log.trace.filterMap\n      fun (src', str') =&gt; if src' == src then some str' else none\n  #check filterSrc\n  -- Logger.filterSrc {Src : Type} (log : Logger Src) (src : Src) [inst‚úù : BEq Src] : List String\n\n  def lenSrc :=\n    log.filterSrc src |&gt;.length\n  #check lenSrc\n  -- Logger.lenSrc {Src : Type} (log : Logger Src) (src : Src) [inst‚úù : BEq Src] : Nat\nend Logger\n```\n\nThe following example demonstrates availability of variables in proofs:\n```lean\nvariable\n  {Œ± : Type}    -- available in the proof as indirectly mentioned through `a`\n  [ToString Œ±]  -- available in the proof as `Œ±` is included\n  (a : Œ±)       -- available in the proof as mentioned in the header\n  {Œ≤ : Type}    -- not available in the proof\n  [ToString Œ≤]  -- not available in the proof\n\ntheorem ex : a = a := rfl\n```\nAfter elaboration of the proof, the following warning will be generated to highlight the unused\nhypothesis:\n```\nincluded section variable '[ToString Œ±]' is not used in 'ex', consider excluding it\n```\nIn such cases, the offending variable declaration should be moved down or into a section so that\nonly theorems that do depend on it follow it until the end of the section.\n</code>",
 "79":
 "<code>HilbertCurve.quadrant_preserved (i n : ‚Ñï) : get_quadrant' i (hilbert_curve (i + 1) n) = get_quadrant i n</code>",
 "78":
 "<code>lt_of_le_of_lt.{u_1} {Œ± : Type u_1} [Preorder Œ±] {a b c : Œ±} (hab : a ‚â§ b) (hbc : b &lt; c) : a &lt; c</code>",
 "77":
 "<code class=\"docstring\">`apply e` tries to match the current goal against the conclusion of `e`'s type.\nIf it succeeds, then the tactic returns as many subgoals as the number of premises that\nhave not been fixed by type inference or type class resolution.\nNon-dependent premises are added before dependent ones.\n\nThe `apply` tactic uses higher-order pattern matching, type class resolution,\nand first-order unification with dependent types.\n</code>",
 "76": "<code>2 ^ i - 1 &lt; 2 ^ i</code>",
 "75":
 "<code>if_pos.{u} {c : Prop} {h : Decidable c} (hc : c) {Œ± : Sort u} {t e : Œ±} : (if c then t else e) = t</code>",
 "74":
 "<code class=\"docstring\">The `have` tactic is for adding hypotheses to the local context of the main goal.\n* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.\n* `have h := e` uses the type of `e` for `t`.\n* `have : t := e` and `have := e` use `this` for the name of the hypothesis.\n* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,\n  where `_` stands for the tactics that follow this one.\n  It is convenient for types that have only one applicable constructor.\n  For example, given `h : p ‚àß q ‚àß r`, `have ‚ü®h‚ÇÅ, h‚ÇÇ, h‚ÇÉ‚ü© := h` produces the\n  hypotheses `h‚ÇÅ : p`, `h‚ÇÇ : q`, and `h‚ÇÉ : r`.\n</code>",
 "73": "<code>HilbertCurve.Quadrant.TOP_RIGHT : Quadrant</code>",
 "72": "<code>HilbertCurve.Quadrant.BOTTOM_RIGHT : Quadrant</code>",
 "71": "<code>HilbertCurve.Quadrant.TOP_LEFT : Quadrant</code>",
 "70":
 "<code>LT.lt.{u} {Œ± : Type u} [self : LT Œ±] : Œ± ‚Üí Œ± ‚Üí Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-than relation: `x &lt; y` \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `&lt;` in identifiers is `lt`.</code>",
 "7": "<code>T3_nat (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) : ‚Ñï √ó ‚Ñï</code>",
 "69":
 "<code>ite.{u} {Œ± : Sort u} (c : Prop) [h : Decidable c] (t e : Œ±) : Œ±</code><span class=\"sep\"></span><code class=\"docstring\">`if c then t else e` is notation for `ite c t e`, \"if-then-else\", which decides to\nreturn `t` or `e` depending on whether `c` is true or false. The explicit argument\n`c : Prop` does not have any actual computational content, but there is an additional\n`[Decidable c]` argument synthesized by typeclass inference which actually\ndetermines how to evaluate `c` to true or false. Write `if h : c then t else e`\ninstead for a \"dependent if-then-else\" `dite`, which allows `t`/`e` to use the fact\nthat `c` is true/false.\n</code>",
 "68": "<code>HilbertCurve.Quadrant.BOTTOM_LEFT : Quadrant</code>",
 "67": "<code>HilbertCurve.T0_nat : ‚Ñï √ó ‚Ñï ‚Üí ‚Ñï √ó ‚Ñï</code>",
 "66": "<code>HilbertCurve.get_quadrant' (i : ‚Ñï) : ‚Ñï √ó ‚Ñï ‚Üí Quadrant</code>",
 "65": "<code>mn ‚â§ (2 ^ i - 1, 2 ^ i - 1)</code>",
 "64":
 "<code>HilbertCurve.get_quadrant'_T0 (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) (h : mn ‚â§ (2 ^ i - 1, 2 ^ i - 1)) :\n  get_quadrant' i (T0_nat mn) = Quadrant.BOTTOM_LEFT</code>",
 "63":
 "<code class=\"docstring\">Makes names from other namespaces visible without writing the namespace prefix.\n\nNames that are made available with `open` are visible within the current `section` or `namespace`\nblock. This makes referring to (type) definitions and theorems easier, but note that it can also\nmake [scoped instances], notations, and attributes from a different namespace available.\n\nThe `open` command can be used in a few different ways:\n\n* `open Some.Namespace.Path1 Some.Namespace.Path2` makes all non-protected names in\n  `Some.Namespace.Path1` and `Some.Namespace.Path2` available without the prefix, so that\n  `Some.Namespace.Path1.x` and `Some.Namespace.Path2.y` can be referred to by writing only `x` and\n  `y`.\n\n* `open Some.Namespace.Path hiding def1 def2` opens all non-protected names in `Some.Namespace.Path`\n  except `def1` and `def2`.\n\n* `open Some.Namespace.Path (def1 def2)` only makes `Some.Namespace.Path.def1` and\n  `Some.Namespace.Path.def2` available without the full prefix, so `Some.Namespace.Path.def3` would\n  be unaffected.\n\n  This works even if `def1` and `def2` are `protected`.\n\n* `open Some.Namespace.Path renaming def1 ‚Üí def1', def2 ‚Üí def2'` same as `open Some.Namespace.Path\n  (def1 def2)` but `def1`/`def2`'s names are changed to `def1'`/`def2'`.\n\n  This works even if `def1` and `def2` are `protected`.\n\n* `open scoped Some.Namespace.Path1 Some.Namespace.Path2` **only** opens [scoped instances],\n  notations, and attributes from `Namespace1` and `Namespace2`; it does **not** make any other name\n  available.\n\n* `open &lt;any of the open shapes above&gt; in` makes the names `open`-ed visible only in the next\n  command or expression.\n\n[scoped instance]: https://lean-lang.org/theorem_proving_in_lean4/type_classes.html#scoped-instances\n(Scoped instances in Theorem Proving in Lean)\n\n\n## Examples\n\n```lean\n/-- SKI combinators https://en.wikipedia.org/wiki/SKI_combinator_calculus -/\nnamespace Combinator.Calculus\n  def I (a : Œ±) : Œ± := a\n  def K (a : Œ±) : Œ≤ ‚Üí Œ± := fun _ =&gt; a\n  def S (x : Œ± ‚Üí Œ≤ ‚Üí Œ≥) (y : Œ± ‚Üí Œ≤) (z : Œ±) : Œ≥ := x z (y z)\nend Combinator.Calculus\n\nsection\n  -- open everything under `Combinator.Calculus`, *i.e.* `I`, `K` and `S`,\n  -- until the section ends\n  open Combinator.Calculus\n\n  theorem SKx_eq_K : S K x = I := rfl\nend\n\n-- open everything under `Combinator.Calculus` only for the next command (the next `theorem`, here)\nopen Combinator.Calculus in\ntheorem SKx_eq_K' : S K x = I := rfl\n\nsection\n  -- open only `S` and `K` under `Combinator.Calculus`\n  open Combinator.Calculus (S K)\n\n  theorem SKxy_eq_y : S K x y = y := rfl\n\n  -- `I` is not in scope, we have to use its full path\n  theorem SKxy_eq_Iy : S K x y = Combinator.Calculus.I y := rfl\nend\n\nsection\n  open Combinator.Calculus\n    renaming\n      I ‚Üí identity,\n      K ‚Üí konstant\n\n  #check identity\n  #check konstant\nend\n\nsection\n  open Combinator.Calculus\n    hiding S\n\n  #check I\n  #check K\nend\n\nsection\n  namespace Demo\n    inductive MyType\n    | val\n\n    namespace N1\n      scoped infix:68 \" ‚âã \" =&gt; BEq.beq\n\n      scoped instance : BEq MyType where\n        beq _ _ := true\n\n      def Alias := MyType\n    end N1\n  end Demo\n\n  -- bring `‚âã` and the instance in scope, but not `Alias`\n  open scoped Demo.N1\n\n  #check Demo.MyType.val == Demo.MyType.val\n  #check Demo.MyType.val ‚âã Demo.MyType.val\n  -- #check Alias -- unknown identifier 'Alias'\nend\n```\n</code>",
 "62":
 "<code>List.range (n : ‚Ñï) : List ‚Ñï</code><span class=\"sep\"></span><code class=\"docstring\">Returns a list of the numbers from `0` to `n` exclusive, in increasing order.\n\n`O(n)`.\n\nExamples:\n* `range 5 = [0, 1, 2, 3, 4]`\n* `range 0 = []`\n* `range 2 = [0, 1]`\n</code>",
 "61":
 "<code>List.map.{u, v} {Œ± : Type u} {Œ≤ : Type v} (f : Œ± ‚Üí Œ≤) (l : List Œ±) : List Œ≤</code><span class=\"sep\"></span><code class=\"docstring\">Applies a function to each element of the list, returning the resulting list of values.\n\n`O(|l|)`.\n\nExamples:\n* `[a, b, c].map f = [f a, f b, f c]`\n* `[].map Nat.succ = []`\n* `[\"one\", \"two\", \"three\"].map (¬∑.length) = [3, 3, 5]`\n* `[\"one\", \"two\", \"three\"].map (¬∑.reverse) = [\"eno\", \"owt\", \"eerht\"]`\n</code>",
 "60":
 "<code class=\"docstring\">`#eval e` evaluates the expression `e` by compiling and evaluating it.\n\n* The command attempts to use `ToExpr`, `Repr`, or `ToString` instances to print the result.\n* If `e` is a monadic value of type `m ty`, then the command tries to adapt the monad `m`\n  to one of the monads that `#eval` supports, which include `IO`, `CoreM`, `MetaM`, `TermElabM`, and `CommandElabM`.\n  Users can define `MonadEval` instances to extend the list of supported monads.\n\nThe `#eval` command gracefully degrades in capability depending on what is imported.\nImporting the `Lean.Elab.Command` module provides full capabilities.\n\nDue to unsoundness, `#eval` refuses to evaluate expressions that depend on `sorry`, even indirectly,\nsince the presence of `sorry` can lead to runtime instability and crashes.\nThis check can be overridden with the `#eval! e` command.\n\nOptions:\n* If `eval.pp` is true (default: true) then tries to use `ToExpr` instances to make use of the\n  usual pretty printer. Otherwise, only tries using `Repr` and `ToString` instances.\n* If `eval.type` is true (default: false) then pretty prints the type of the evaluated value.\n* If `eval.derive.repr` is true (default: true) then attempts to auto-derive a `Repr` instance\n  when there is no other way to print the result.\n\nSee also: `#reduce e` for evaluation by term reduction.\n</code>",
 "6": "<code>T2_nat (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) : ‚Ñï √ó ‚Ñï</code>",
 "59":
 "<code class=\"docstring\">`/-- ... -/ #guard_msgs in cmd` captures the messages generated by the command `cmd`\nand checks that they match the contents of the docstring.\n\nBasic example:\n```lean\n/--\nerror: unknown identifier 'x'\n-/\n#guard_msgs in\nexample : Œ± := x\n```\nThis checks that there is such an error and then consumes the message.\n\nBy default, the command captures all messages, but the filter condition can be adjusted.\nFor example, we can select only warnings:\n```lean\n/--\nwarning: declaration uses 'sorry'\n-/\n#guard_msgs(warning) in\nexample : Œ± := sorry\n```\nor only errors\n```lean\n#guard_msgs(error) in\nexample : Œ± := sorry\n```\nIn the previous example, since warnings are not captured there is a warning on `sorry`.\nWe can drop the warning completely with\n```lean\n#guard_msgs(error, drop warning) in\nexample : Œ± := sorry\n```\n\nIn general, `#guard_msgs` accepts a comma-separated list of configuration clauses in parentheses:\n```\n#guard_msgs (configElt,*) in cmd\n```\nBy default, the configuration list is `(check all, whitespace := normalized, ordering := exact)`.\n\nMessage filters select messages by severity:\n- `info`, `warning`, `error`: (non-trace) messages with the given severity level.\n- `trace`: trace messages\n- `all`: all messages.\n\nThe filters can be prefixed with the action to take:\n- `check` (the default): capture and check the message\n- `drop`: drop the message\n- `pass`: let the message pass through\n\nIf no filter is specified, `check all` is assumed.  Otherwise, these filters are processed in\nleft-to-right order, with an implicit `pass all` at the end.\n\nWhitespace handling (after trimming leading and trailing whitespace):\n- `whitespace := exact` requires an exact whitespace match.\n- `whitespace := normalized` converts all newline characters to a space before matching\n  (the default). This allows breaking long lines.\n- `whitespace := lax` collapses whitespace to a single space before matching.\n\nMessage ordering:\n- `ordering := exact` uses the exact ordering of the messages (the default).\n- `ordering := sorted` sorts the messages in lexicographic order.\n  This helps with testing commands that are non-deterministic in their ordering.\n\nFor example, `#guard_msgs (error, drop all) in cmd` means to check warnings and drop\neverything else.\n\nThe command elaborator has special support for `#guard_msgs` for linting.\nThe `#guard_msgs` itself wants to capture linter warnings,\nso it elaborates the command it is attached to as if it were a top-level command.\nHowever, the command elaborator runs linters for *all* top-level commands,\nwhich would include `#guard_msgs` itself, and would cause duplicate and/or uncaptured linter warnings.\nThe top-level command elaborator only runs the linters if `#guard_msgs` is not present.\n</code>",
 "58":
 "<code class=\"docstring\">`let` is used to declare a local definition. Example:\n```\nlet x := 1\nlet y := x + 1\nx + y\n```\nSince functions are first class citizens in Lean, you can use `let` to declare\nlocal functions too.\n```\nlet double := fun x =&gt; 2*x\ndouble (double 3)\n```\nFor recursive definitions, you should use `let rec`.\nYou can also perform pattern matching using `let`. For example,\nassume `p` has type `Nat √ó Nat`, then you can write\n```\nlet (x, y) := p\nx + y\n```\n</code>",
 "57":
 "<code class=\"docstring\">Pattern matching. `match e, ... with | p, ... =&gt; f | ...` matches each given\nterm `e` against each pattern `p` of a match alternative. When all patterns\nof an alternative match, the `match` term evaluates to the value of the\ncorresponding right-hand side `f` with the pattern variables bound to the\nrespective matched values.\nIf used as `match h : e, ... with | p, ... =&gt; f | ...`, `h : e = p` is available\nwithin `f`.\n\nWhen not constructing a proof, `match` does not automatically substitute variables\nmatched on in dependent variables' types. Use `match (generalizing := true) ...` to\nenforce this.\n\nSyntax quotations can also be used in a pattern match.\nThis matches a `Syntax` value against quotations, pattern variables, or `_`.\n\nQuoted identifiers only match identical identifiers - custom matching such as by the preresolved\nnames only should be done explicitly.\n\n`Syntax.atom`s are ignored during matching by default except when part of a built-in literal.\nFor users introducing new atoms, we recommend wrapping them in dedicated syntax kinds if they\nshould participate in matching.\nFor example, in\n```lean\nsyntax \"c\" (\"foo\" &lt;|&gt; \"bar\") ...\n```\n`foo` and `bar` are indistinguishable during matching, but in\n```lean\nsyntax foo := \"foo\"\nsyntax \"c\" (foo &lt;|&gt; \"bar\") ...\n```\nthey are not.\n</code>",
 "56":
 "<code>Nat.succ (n : ‚Ñï) : ‚Ñï</code><span class=\"sep\"></span><code class=\"docstring\">The successor of a natural number `n`.\n\nUsing `Nat.succ n` should usually be avoided in favor of `n + 1`, which is the [simp normal\nform](https://lean-lang.org/doc/reference/4.21.0-rc3/find/?domain=Verso.Genre.Manual.section&name=simp-normal-forms).\n</code>",
 "55": "<code>hilbert_curve : ‚Ñï ‚Üí ‚Ñï ‚Üí ‚Ñï √ó ‚Ñï</code>",
 "54":
 "<code class=\"docstring\">`if c then t else e` is notation for `ite c t e`, \"if-then-else\", which decides to\nreturn `t` or `e` depending on whether `c` is true or false. The explicit argument\n`c : Prop` does not have any actual computational content, but there is an additional\n`[Decidable c]` argument synthesized by typeclass inference which actually\ndetermines how to evaluate `c` to true or false. Write `if h : c then t else e`\ninstead for a \"dependent if-then-else\" `dite`, which allows `t`/`e` to use the fact\nthat `c` is true/false.\n</code>",
 "53": "<code>get_quadrant (i n : ‚Ñï) : Quadrant</code>",
 "52":
 "<code>DecidableEq.{u} (Œ± : Sort u) : Sort (max 1 u)</code><span class=\"sep\"></span><code class=\"docstring\">Propositional equality is `Decidable` for all elements of a type.\n\nIn other words, an instance of `DecidableEq Œ±` is a means of deciding the proposition `a = b` is\nfor all `a b : Œ±`.\n</code>",
 "51": "<code>Quadrant.BOTTOM_RIGHT : Quadrant</code>",
 "50": "<code>Quadrant.TOP_RIGHT : Quadrant</code>",
 "5": "<code>‚Ñï √ó ‚Ñï</code>",
 "49": "<code>Quadrant.TOP_LEFT : Quadrant</code>",
 "48": "<code>Quadrant.BOTTOM_LEFT : Quadrant</code>",
 "47": "<code>Quadrant : Type</code>",
 "46":
 "<code class=\"docstring\">In Lean, every concrete type other than the universes\nand every type constructor other than dependent arrows\nis an instance of a general family of type constructions known as inductive types.\nIt is remarkable that it is possible to construct a substantial edifice of mathematics\nbased on nothing more than the type universes, dependent arrow types, and inductive types;\neverything else follows from those.\nIntuitively, an inductive type is built up from a specified list of constructors.\nFor example, `List Œ±` is the list of elements of type `Œ±`, and is defined as follows:\n```\ninductive List (Œ± : Type u) where\n| nil\n| cons (head : Œ±) (tail : List Œ±)\n```\nA list of elements of type `Œ±` is either the empty list, `nil`,\nor an element `head : Œ±` followed by a list `tail : List Œ±`.\nSee [Inductive types](https://lean-lang.org/theorem_proving_in_lean4/inductive_types.html)\nfor more information.\n</code>",
 "45":
 "<code>Nat.cast_sub.{u} {R : Type u} [AddGroupWithOne R] {m n : ‚Ñï} (h : m ‚â§ n) : ‚Üë(n - m) = ‚Üën - ‚Üëm</code>",
 "44":
 "<code>‚àÄ (p v : R √ó R),\n  (fun mn =&gt; (2 ^ (i + 1) - 1 - mn.2, 2 ^ i - 1 - mn.1)) (v +·µ• p) =\n    (-HilbertCurve.T0) v +·µ• (fun mn =&gt; (2 ^ (i + 1) - 1 - mn.2, 2 ^ i - 1 - mn.1)) p</code>",
 "43":
 "<code>AffineMap.mk.{u_1, u_2, u_3, u_4, u_5} {k : Type u_1} {V1 : Type u_2} {P1 : Type u_3} {V2 : Type u_4} {P2 : Type u_5}\n  [Ring k] [AddCommGroup V1] [Module k V1] [AddTorsor V1 P1] [AddCommGroup V2] [Module k V2] [AddTorsor V2 P2]\n  (toFun : P1 ‚Üí P2) (linear : V1 ‚Üí‚Çó[k] V2) (map_vadd' : ‚àÄ (p : P1) (v : V1), toFun (v +·µ• p) = linear v +·µ• toFun p) :\n  P1 ‚Üí·µÉ[k] P2</code>",
 "42":
 "<code>RtimesR.coe_prod.{u_1} {R : Type u_1} [Ring R] (p : ‚Ñï √ó ‚Ñï) : ‚Üëp = (‚Üëp.1, ‚Üëp.2)</code>",
 "41":
 "<code>Prod.mk_sub_mk.{u_6, u_7} {G : Type u_6} {H : Type u_7} [Sub G] [Sub H] (x‚ÇÅ x‚ÇÇ : G) (y‚ÇÅ y‚ÇÇ : H) :\n  (x‚ÇÅ, y‚ÇÅ) - (x‚ÇÇ, y‚ÇÇ) = (x‚ÇÅ - x‚ÇÇ, y‚ÇÅ - y‚ÇÇ)</code>",
 "40":
 "<code>LE.le.{u} {Œ± : Type u} [self : LE Œ±] : Œ± ‚Üí Œ± ‚Üí Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-equal relation: `x ‚â§ y` \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `‚â§` in identifiers is `le`.\n\n * The recommended spelling of `&lt;=` in identifiers is `le` (prefer `‚â§` over `&lt;=`).</code>",
 "4": "<code>T1_nat (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) : ‚Ñï √ó ‚Ñï</code>",
 "39": "<code>mn.2 ‚â§ 2 ^ (i + 1) - 1</code>",
 "38": "<code>mn.1 ‚â§ 2 ^ i - 1</code>",
 "37":
 "<code>T3_cast_nat.{u_1} {R : Type u_1} [Ring R] (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) (h1 : mn.1 ‚â§ 2 ^ i - 1) (h2 : mn.2 ‚â§ 2 ^ (i + 1) - 1) :\n  (T3 i) ‚Üëmn = ‚Üë(T3_nat i mn)</code>",
 "36":
 "<code>neg_add.{u_1} {Œ± : Type u_1} [SubtractionCommMonoid Œ±] (a b : Œ±) : -(a + b) = -a + -b</code>",
 "35":
 "<code>add_assoc.{u_1} {G : Type u_1} [AddSemigroup G] (a b c : G) : a + b + c = a + (b + c)</code>",
 "34":
 "<code>sub_eq_add_neg.{u_1} {G : Type u_1} [SubNegMonoid G] (a b : G) : a - b = a + -b</code><span class=\"sep\"></span><code class=\"docstring\">Subtracting an element is the same as adding by its negative.\nThis is a duplicate of `SubNegMonoid.sub_eq_add_neg` ensuring that the types unfold better.</code>",
 "332":
 "<code>Filter.EventuallyEq.{u_1, u_2} {Œ± : Type u_1} {Œ≤ : Type u_2} (l : Filter Œ±) (f g : Œ± ‚Üí Œ≤) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">Two functions `f` and `g` are *eventually equal* along a filter `l` if the set of `x` such that\n`f x = g x` belongs to `l`. </code>",
 "331":
 "<code>Filter.Tendsto (fun i =&gt; (T3_real i) (normalized_hilbert_curve i (4 * f i - 3))) Filter.atTop\n  (nhds (limit_hilbert_curve t))</code>",
 "330":
 "<code>Filter.tendsto_congr'.{u_1, u_2} {Œ± : Type u_1} {Œ≤ : Type u_2} {f‚ÇÅ f‚ÇÇ : Œ± ‚Üí Œ≤} {l‚ÇÅ : Filter Œ±} {l‚ÇÇ : Filter Œ≤}\n  (hl : f‚ÇÅ =·∂†[l‚ÇÅ] f‚ÇÇ) : Filter.Tendsto f‚ÇÅ l‚ÇÅ l‚ÇÇ ‚Üî Filter.Tendsto f‚ÇÇ l‚ÇÅ l‚ÇÇ</code>",
 "33":
 "<code>add_comm.{u_1} {G : Type u_1} [AddCommMagma G] (a b : G) : a + b = b + a</code>",
 "329":
 "<code>(4 * ‚Üë(fnat i) - 3 * ‚Üë(hilbert_length i)) / ‚Üë(hilbert_length i) = 4 * ‚Üë(fnat i) / ‚Üë(hilbert_length i) - 3</code>",
 "328":
 "<code class=\"docstring\">The goal of `field_simp` is to reduce an expression in a field to an expression of the form `n / d`\nwhere neither `n` nor `d` contains any division symbol, just using the simplifier (with a carefully\ncrafted simpset named `field_simps`) to reduce the number of division symbols whenever possible by\niterating the following steps:\n\n- write an inverse as a division\n- in any product, move the division to the right\n- if there are several divisions in a product, group them together at the end and write them as a\n  single division\n- reduce a sum to a common denominator\n\nIf the goal is an equality, this simpset will also clear the denominators, so that the proof\ncan normally be concluded by an application of `ring`.\n\n`field_simp [hx, hy]` is a short form for\n`simp (disch := field_simp_discharge) [-one_div, -one_divp, -mul_eq_zero, hx, hy, field_simps]`\n\nNote that this naive algorithm will not try to detect common factors in denominators to reduce the\ncomplexity of the resulting expression. Instead, it relies on the ability of `ring` to handle\ncomplicated expressions in the next step.\n\nAs always with the simplifier, reduction steps will only be applied if the preconditions of the\nlemmas can be checked. This means that proofs that denominators are nonzero should be included. The\nfact that a product is nonzero when all factors are, and that a power of a nonzero number is\nnonzero, are included in the simpset, but more complicated assertions (especially dealing with sums)\nshould be given explicitly. If your expression is not completely reduced by the simplifier\ninvocation, check the denominators of the resulting expression and provide proofs that they are\nnonzero to enable further progress.\n\nTo check that denominators are nonzero, `field_simp` will look for facts in the context, and\nwill try to apply `norm_num` to close numerical goals.\n\nThe invocation of `field_simp` removes the lemma `one_div` from the simpset, as this lemma\nworks against the algorithm explained above. It also removes\n`mul_eq_zero : x * y = 0 ‚Üî x = 0 ‚à® y = 0`, as `norm_num` can not work on disjunctions to\nclose goals of the form `24 ‚â† 0`, and replaces it with `mul_ne_zero : x ‚â† 0 ‚Üí y ‚â† 0 ‚Üí x * y ‚â† 0`\ncreating two goals instead of a disjunction.\n\nFor example,\n```lean\nexample (a b c d x y : ‚ÑÇ) (hx : x ‚â† 0) (hy : y ‚â† 0) :\n    a + b / x + c / x^2 + d / x^3 = a + x‚Åª¬π * (y * b / y + (d / x + c) / x) := by\n  field_simp\n  ring\n```\n\nMoreover, the `field_simp` tactic can also take care of inverses of units in\na general (commutative) monoid/ring and partial division `/‚Çö`, see `Algebra.Group.Units`\nfor the definition. Analogue to the case above, the lemma `one_divp` is removed from the simpset\nas this works against the algorithm. If you have objects with an `IsUnit x` instance like\n`(x : R) (hx : IsUnit x)`, you should lift them with\n`lift x to RÀ£ using id hx; rw [IsUnit.unit_of_val_units] clear hx`\nbefore using `field_simp`.\n\nSee also the `cancel_denoms` tactic, which tries to do a similar simplification for expressions\nthat have numerals in denominators.\nThe tactics are not related: `cancel_denoms` will only handle numeric denominators, and will try to\nentirely remove (numeric) division from the expression by multiplying by a factor.\n</code>",
 "327": "<code>0 &lt; hilbert_length i</code>",
 "326":
 "<code>HilbertCurve.hilbert_length_pos (i : ‚Ñï) : 0 &lt; hilbert_length i</code>",
 "325":
 "<code>HilbertCurve.normalized_recurse_bottom_right {i j : ‚Ñï} (h : get_quadrant i (4 * j) = Quadrant.BOTTOM_RIGHT) :\n  normalized_hilbert_curve (i + 1) (‚Üëj / ‚Üë(hilbert_length i)) =\n    (T3_real i) (normalized_hilbert_curve i ((4 * ‚Üëj - 3 * ‚Üë(hilbert_length i)) / ‚Üë(hilbert_length i)))</code>",
 "324": "<code>get_quadrant i (4 * fnat i) = Quadrant.BOTTOM_RIGHT</code>",
 "323":
 "<code>mul_div_assoc.{u_1} {G : Type u_1} [DivInvMonoid G] (a b c : G) : a * b / c = a * (b / c)</code>",
 "322":
 "<code>GE.ge.{u} {Œ± : Type u} [LE Œ±] (a b : Œ±) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`a ‚â• b` is an abbreviation for `b ‚â§ a`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `‚â•` in identifiers is `ge`.\n\n * The recommended spelling of `&gt;=` in identifiers is `ge` (prefer `‚â•` over `&gt;=`).</code>",
 "321": "<code>i ‚â• 1</code>",
 "320":
 "<code>Filter.eventually_atTop.{u_3} {Œ± : Type u_3} [Preorder Œ±] [IsDirected Œ± fun x1 x2 =&gt; x1 ‚â§ x2] {p : Œ± ‚Üí Prop}\n  [Nonempty Œ±] : (‚àÄ·∂† (x : Œ±) in Filter.atTop, p x) ‚Üî ‚àÉ a, ‚àÄ b ‚â• a, p b</code>",
 "32":
 "<code class=\"docstring\">`rw` is like `rewrite`, but also tries to close the goal by \"cheap\" (reducible) `rfl` afterwards.\n</code>",
 "319":
 "<code>(fun i =&gt; normalized_hilbert_curve (i + 1) (f i)) =·∂†[Filter.atTop] fun i =&gt;\n  (T3_real i) (normalized_hilbert_curve i (4 * f i - 3))</code>",
 "318":
 "<code>HilbertCurve.T3_real_tendsto_uniformly : TendstoUniformly (fun i x =&gt; (T3_real i) x) (‚áëT3_real_lim) Filter.atTop</code>",
 "317":
 "<code>Filter.Tendsto (fun i =&gt; normalized_hilbert_curve i (4 * f i - 3)) Filter.atTop (nhds (limit_hilbert_curve (4 * t - 3)))</code>",
 "316":
 "<code>ContinuousAffineMap.continuous.{u_1, u_2, u_3, u_4, u_5} {R : Type u_1} {V : Type u_2} {W : Type u_3} {P : Type u_4}\n  {Q : Type u_5} [Ring R] [AddCommGroup V] [Module R V] [TopologicalSpace P] [AddTorsor V P] [AddCommGroup W]\n  [Module R W] [TopologicalSpace Q] [AddTorsor W Q] (f : P ‚Üí·¥¨[R] Q) : Continuous ‚áëf</code>",
 "315":
 "<code>Filter.Tendsto.const_mul.{u_2, u_3} {Œ± : Type u_2} {M : Type u_3} [TopologicalSpace M] [Mul M] [ContinuousMul M] (b : M)\n  {c : M} {f : Œ± ‚Üí M} {l : Filter Œ±} (h : Filter.Tendsto (fun k =&gt; f k) l (nhds c)) :\n  Filter.Tendsto (fun k =&gt; b * f k) l (nhds (b * c))</code>",
 "314":
 "<code>Filter.Tendsto.sub_const.{u, w} {G : Type w} {Œ± : Type u} [TopologicalSpace G] [Sub G] [ContinuousSub G] {c : G}\n  {f : Œ± ‚Üí G} {l : Filter Œ±} (h : Filter.Tendsto f l (nhds c)) (b : G) :\n  Filter.Tendsto (fun x =&gt; f x - b) l (nhds (c - b))</code>",
 "313": "<code>HilbertCurve.T3_real (i : ‚Ñï) : ‚Ñù √ó ‚Ñù ‚Üí·¥¨[‚Ñù] ‚Ñù √ó ‚Ñù</code>",
 "312":
 "<code>Filter.Tendsto (fun i =&gt; (T3_real i) (normalized_hilbert_curve i (4 * f i - 3))) Filter.atTop\n  (nhds (T3_real_lim (limit_hilbert_curve (4 * t - 3))))</code>",
 "311":
 "<code>Filter.tendsto_add_atTop_nat (k : ‚Ñï) : Filter.Tendsto (fun a =&gt; a + k) Filter.atTop Filter.atTop</code>",
 "310":
 "<code>ContinuousAt.{u_1, u_2} {X : Type u_1} {Y : Type u_2} [TopologicalSpace X] [TopologicalSpace Y] (f : X ‚Üí Y) (x : X) :\n  Prop</code><span class=\"sep\"></span><code class=\"docstring\">A function between topological spaces is continuous at a point `x‚ÇÄ`\nif `f x` tends to `f x‚ÇÄ` when `x` tends to `x‚ÇÄ`. </code>",
 "31":
 "<code class=\"docstring\">The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or\nnon-dependent hypotheses. It has many variants:\n- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.\n- `simp [h‚ÇÅ, h‚ÇÇ, ..., h‚Çô]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]` and the given `h·µ¢`'s, where the `h·µ¢`'s are expressions.-\n- If an `h·µ¢` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated\n  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.\n- `simp [*]` simplifies the main goal target using the lemmas tagged with the\n  attribute `[simp]` and all hypotheses.\n- `simp only [h‚ÇÅ, h‚ÇÇ, ..., h‚Çô]` is like `simp [h‚ÇÅ, h‚ÇÇ, ..., h‚Çô]` but does not use `[simp]` lemmas.\n- `simp [-id‚ÇÅ, ..., -id‚Çô]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]`, but removes the ones named `id·µ¢`.\n- `simp at h‚ÇÅ h‚ÇÇ ... h‚Çô` simplifies the hypotheses `h‚ÇÅ : T‚ÇÅ` ... `h‚Çô : T‚Çô`. If\n  the target or another hypothesis depends on `h·µ¢`, a new simplified hypothesis\n  `h·µ¢` is introduced, but the old one remains in the local context.\n- `simp at *` simplifies all the hypotheses and the target.\n- `simp [*] at *` simplifies target and all (propositional) hypotheses using the\n  other hypotheses.\n</code>",
 "309":
 "<code>TendstoUniformly.{u_1, u_2, u_4} {Œ± : Type u_1} {Œ≤ : Type u_2} {Œπ : Type u_4} [UniformSpace Œ≤] (F : Œπ ‚Üí Œ± ‚Üí Œ≤)\n  (f : Œ± ‚Üí Œ≤) (p : Filter Œπ) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A sequence of functions `F‚Çô` converges uniformly to a limiting function `f` with respect to a\nfilter `p` if, for any entourage of the diagonal `u`, one has `p`-eventually\n`(f x, F‚Çô x) ‚àà u` for all `x`. </code>",
 "308":
 "<code>Filter.Tendsto (fun i =&gt; normalized_hilbert_curve (i + 1) (f i)) Filter.atTop (nhds (limit_hilbert_curve t))</code>",
 "307": "<code>Filter.Tendsto f Filter.atTop (nhds t)</code>",
 "306": "<code>f = fun i =&gt; ‚Üë(fnat i) / ‚Üë(hilbert_length i)</code>",
 "305":
 "<code>‚àÄ i ‚â• 1, 3 * hilbert_length i ‚â§ 4 * fnat i ‚àß 4 * fnat i &lt; (3 + 1) * hilbert_length i</code>",
 "304":
 "<code>Filter.Tendsto (fun i =&gt; ‚Üë(fnat i) / ‚Üë(hilbert_length i)) Filter.atTop (nhds t)</code>",
 "303":
 "<code>HilbertCurve.sequence_exists (t : ‚Ñù) (n : ‚Ñï) (h : ‚Üën / 4 ‚â§ t) (h' : t ‚â§ (‚Üën + 1) / 4) :\n  ‚àÉ f,\n    Filter.Tendsto (fun i =&gt; ‚Üë(f i) / ‚Üë(hilbert_length i)) Filter.atTop (nhds t) ‚àß\n      ‚àÄ i ‚â• 1, n * hilbert_length i ‚â§ 4 * f i ‚àß 4 * f i &lt; (n + 1) * hilbert_length i</code>",
 "302": "<code>HilbertCurve.T3_real_lim : ‚Ñù √ó ‚Ñù ‚Üí·¥¨[‚Ñù] ‚Ñù √ó ‚Ñù</code>",
 "301": "<code>t ‚àà Set.Icc (3 / 4) 1</code>",
 "300":
 "<code>HilbertCurve.limit_hilbert_recurse_bottom_right (t : ‚Ñù) (h : t ‚àà Set.Icc (3 / 4) 1) :\n  limit_hilbert_curve t = T3_real_lim (limit_hilbert_curve (4 * t - 3))</code>",
 "30":
 "<code>Neg.neg.{u} {Œ± : Type u} [self : Neg Œ±] : Œ± ‚Üí Œ±</code><span class=\"sep\"></span><code class=\"docstring\">`-a` computes the negative or opposite of `a`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `-` in identifiers is `neg` (when used as a unary operator).</code>",
 "3":
 "<code>Prod.swap.{u_1, u_2} {Œ± : Type u_1} {Œ≤ : Type u_2} : Œ± √ó Œ≤ ‚Üí Œ≤ √ó Œ±</code><span class=\"sep\"></span><code class=\"docstring\">Swaps the elements in a pair.\n\nExamples:\n* `(1, 2).swap = (2, 1)`\n* `(\"orange\", -87).swap = (-87, \"orange\")`\n</code>",
 "299": "<code>t ‚â§ (‚Üën + 1) / 4</code>",
 "298": "<code>‚Üën / 4 ‚â§ t</code>",
 "297":
 "<code>sequence_exists (t : ‚Ñù) (n : ‚Ñï) (h : ‚Üën / 4 ‚â§ t) (h' : t ‚â§ (‚Üën + 1) / 4) :\n  ‚àÉ f,\n    Filter.Tendsto (fun i =&gt; ‚Üë(f i) / ‚Üë(hilbert_length i)) Filter.atTop (nhds t) ‚àß\n      ‚àÄ i ‚â• 1, n * hilbert_length i ‚â§ 4 * f i ‚àß 4 * f i &lt; (n + 1) * hilbert_length i</code>",
 "296":
 "<code>LinearMap.mk.{u_14, u_15, u_16, u_17} {R : Type u_14} {S : Type u_15} [Semiring R] [Semiring S] {œÉ : R ‚Üí+* S}\n  {M : Type u_16} {M‚ÇÇ : Type u_17} [AddCommMonoid M] [AddCommMonoid M‚ÇÇ] [Module R M] [Module S M‚ÇÇ] (toAddHom : M ‚Üí‚Çô+ M‚ÇÇ)\n  (map_smul' : ‚àÄ (m : R) (x : M), toAddHom.toFun (m ‚Ä¢ x) = œÉ m ‚Ä¢ toAddHom.toFun x) : M ‚Üí‚Çõ‚Çó[œÉ] M‚ÇÇ</code>",
 "295":
 "<code>‚àÄ (p v : ‚Ñù √ó ‚Ñù),\n  (1, 1 / 2) - (1 / 2) ‚Ä¢ (v +·µ• p).swap =\n    (-(1 / 2) ‚Ä¢ { toFun := Prod.swap, map_add' := ‚ãØ, map_smul' := ‚ãØ }) v +·µ• (1, 1 / 2) - (1 / 2) ‚Ä¢ p.swap</code>",
 "294":
 "<code>‚àÄ (m : ‚Ñù) (x : ‚Ñù √ó ‚Ñù), (m ‚Ä¢ x).swap = (RingHom.id ‚Ñù) m ‚Ä¢ x.swap</code><span class=\"sep\"></span><code class=\"docstring\">The proposition that the function commutes with the actions. </code>",
 "293":
 "<code>‚àÄ (x y : ‚Ñù √ó ‚Ñù), (x + y).swap = x.swap + y.swap</code><span class=\"sep\"></span><code class=\"docstring\">The proposition that the function preserves addition </code>",
 "292": "<code>‚Ñù √ó ‚Ñù ‚Üí‚Çó[‚Ñù] ‚Ñù √ó ‚Ñù</code>",
 "291": "<code>‚Ñù √ó ‚Ñù ‚Üí ‚Ñù √ó ‚Ñù</code>",
 "290": "<code>T3_real_lim : ‚Ñù √ó ‚Ñù ‚Üí·¥¨[‚Ñù] ‚Ñù √ó ‚Ñù</code>",
 "29":
 "<code>Eq.{u_1} {Œ± : Sort u_1} : Œ± ‚Üí Œ± ‚Üí Prop</code><span class=\"sep\"></span><code class=\"docstring\">The equality relation. It has one introduction rule, `Eq.refl`.\nWe use `a = b` as notation for `Eq a b`.\nA fundamental property of equality is that it is an equivalence relation.\n```\nvariable (Œ± : Type) (a b c d : Œ±)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\n\nexample : a = d :=\n  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd\n```\nEquality is much more than an equivalence relation, however. It has the important property that every assertion\nrespects the equivalence, in the sense that we can substitute equal expressions without changing the truth value.\nThat is, given `h1 : a = b` and `h2 : p a`, we can construct a proof for `p b` using substitution: `Eq.subst h1 h2`.\nExample:\n```\nexample (Œ± : Type) (a b : Œ±) (p : Œ± ‚Üí Prop)\n        (h1 : a = b) (h2 : p a) : p b :=\n  Eq.subst h1 h2\n\nexample (Œ± : Type) (a b : Œ±) (p : Œ± ‚Üí Prop)\n    (h1 : a = b) (h2 : p a) : p b :=\n  h1 ‚ñ∏ h2\n```\nThe triangle in the second presentation is a macro built on top of `Eq.subst` and `Eq.symm`, and you can enter it by typing `\\t`.\nFor more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `=` in identifiers is `eq`.</code>",
 "289":
 "<code>AffineMap.comp.{u_1, u_2, u_3, u_4, u_5, u_6, u_7} {k : Type u_1} {V1 : Type u_2} {P1 : Type u_3} {V2 : Type u_4}\n  {P2 : Type u_5} {V3 : Type u_6} {P3 : Type u_7} [Ring k] [AddCommGroup V1] [Module k V1] [AddTorsor V1 P1]\n  [AddCommGroup V2] [Module k V2] [AddTorsor V2 P2] [AddCommGroup V3] [Module k V3] [AddTorsor V3 P3] (f : P2 ‚Üí·µÉ[k] P3)\n  (g : P1 ‚Üí·µÉ[k] P2) : P1 ‚Üí·µÉ[k] P3</code><span class=\"sep\"></span><code class=\"docstring\">Composition of affine maps. </code>",
 "288":
 "<code>LinearMap.toAffineMap.{u_1, u_2, u_3} {k : Type u_1} {V‚ÇÅ : Type u_2} {V‚ÇÇ : Type u_3} [Ring k] [AddCommGroup V‚ÇÅ]\n  [Module k V‚ÇÅ] [AddCommGroup V‚ÇÇ] [Module k V‚ÇÇ] (f : V‚ÇÅ ‚Üí‚Çó[k] V‚ÇÇ) : V‚ÇÅ ‚Üí·µÉ[k] V‚ÇÇ</code><span class=\"sep\"></span><code class=\"docstring\">Reinterpret a linear map as an affine map. </code>",
 "287":
 "<code>AffineMap.toContinuousAffineMap.{u, v, w} {ùïú : Type u} [hnorm : NontriviallyNormedField ùïú] {E : Type v} [AddCommGroup E]\n  [Module ùïú E] [TopologicalSpace E] [IsTopologicalAddGroup E] [ContinuousSMul ùïú E] {F : Type w} [AddCommGroup F]\n  [Module ùïú F] [TopologicalSpace F] [IsTopologicalAddGroup F] [ContinuousSMul ùïú F] [CompleteSpace ùïú] [T2Space E]\n  [FiniteDimensional ùïú E] (f : E ‚Üí·µÉ[ùïú] F) : E ‚Üí·¥¨[ùïú] F</code>",
 "286":
 "<code>LinearMap.id.{u_1, u_8} {R : Type u_1} {M : Type u_8} [Semiring R] [AddCommMonoid M] [Module R M] : M ‚Üí‚Çó[R] M</code><span class=\"sep\"></span><code class=\"docstring\">Identity map as a `LinearMap` </code>",
 "285": "<code>‚Ñù √ó ‚Ñù ‚Üí‚Çó[‚Ñù] ‚Ñù √ó ‚Ñù</code>",
 "284": "<code>T3_real (i : ‚Ñï) : ‚Ñù √ó ‚Ñù ‚Üí·¥¨[‚Ñù] ‚Ñù √ó ‚Ñù</code>",
 "283":
 "<code>HilbertCurve.norm_hilbert_inv_dist (i : ‚Ñï) (x : ‚Ñù √ó ‚Ñù) (xh : x ‚àà Set.Icc 0 1) :\n  dist x (normalized_hilbert_curve i (norm_hilbert_inv i x xh)) ‚â§ (2 ^ i)‚Åª¬π</code><span class=\"sep\"></span><code class=\"docstring\">norm_hilbert_inv is an approximately inverse normalized_hilbert_curve\n</code>",
 "282":
 "<code>Filter.Tendsto (fun n =&gt; (2 ^ n)‚Åª¬π) Filter.atTop (nhds 0)</code>",
 "281":
 "<code>dist_nonneg.{u} {Œ± : Type u} [PseudoMetricSpace Œ±] {x y : Œ±} : 0 ‚â§ dist x y</code>",
 "280":
 "<code>squeeze_zero.{u_3} {Œ± : Type u_3} {f g : Œ± ‚Üí ‚Ñù} {t‚ÇÄ : Filter Œ±} (hf : ‚àÄ (t : Œ±), 0 ‚â§ f t) (hft : ‚àÄ (t : Œ±), f t ‚â§ g t)\n  (g0 : Filter.Tendsto g t‚ÇÄ (nhds 0)) : Filter.Tendsto f t‚ÇÄ (nhds 0)</code><span class=\"sep\"></span><code class=\"docstring\">Special case of the sandwich lemma; see `tendsto_of_tendsto_of_tendsto_of_le_of_le`\nand `tendsto_of_tendsto_of_tendsto_of_le_of_le'` for the general case. </code>",
 "28":
 "<code>HVAdd.hVAdd.{u, v, w} {Œ± : Type u} {Œ≤ : Type v} {Œ≥ : outParam (Type w)} [self : HVAdd Œ± Œ≤ Œ≥] : Œ± ‚Üí Œ≤ ‚Üí Œ≥</code><span class=\"sep\"></span><code class=\"docstring\">`a +·µ• b` computes the sum of `a` and `b`.\nThe meaning of this notation is type-dependent. </code>",
 "279":
 "<code>Max.max.{u} {Œ± : Type u} [self : Max Œ±] : Œ± ‚Üí Œ± ‚Üí Œ±</code><span class=\"sep\"></span><code class=\"docstring\">Returns the greater of its two arguments. </code>",
 "278":
 "<code>abs.{u_1} {Œ± : Type u_1} [Lattice Œ±] [AddGroup Œ±] (a : Œ±) : Œ±</code><span class=\"sep\"></span><code class=\"docstring\">`abs a`, denoted `|a|`, is the absolute value of `a`</code>",
 "277":
 "<code>tendsto_pow_atTop_nhds_zero_of_abs_lt_one {r : ‚Ñù} (h : |r| &lt; 1) : Filter.Tendsto (fun n =&gt; r ^ n) Filter.atTop (nhds 0)</code>",
 "276":
 "<code>tendsto_iff_dist_tendsto_zero.{u, v} {Œ± : Type u} {Œ≤ : Type v} [PseudoMetricSpace Œ±] {f : Œ≤ ‚Üí Œ±} {x : Filter Œ≤}\n  {a : Œ±} : Filter.Tendsto f x (nhds a) ‚Üî Filter.Tendsto (fun b =&gt; dist (f b) a) x (nhds 0)</code>",
 "275":
 "<code>Filter.tendsto_iff_seq_tendsto.{u_1, u_2} {Œ± : Type u_1} {Œ≤ : Type u_2} {f : Œ± ‚Üí Œ≤} {k : Filter Œ±} {l : Filter Œ≤}\n  [k.IsCountablyGenerated] :\n  Filter.Tendsto f k l ‚Üî ‚àÄ (x : ‚Ñï ‚Üí Œ±), Filter.Tendsto x Filter.atTop k ‚Üí Filter.Tendsto (f ‚àò x) Filter.atTop l</code><span class=\"sep\"></span><code class=\"docstring\">An abstract version of continuity of sequentially continuous functions on metric spaces:\nif a filter `k` is countably generated then `Tendsto f k l` iff for every sequence `u`\nconverging to `k`, `f ‚àò u` tends to `l`. </code>",
 "274":
 "<code>tendsto_nhds_unique.{u_1, u_2} {X : Type u_1} {Y : Type u_2} [TopologicalSpace X] [T2Space X] {f : Y ‚Üí X} {l : Filter Y}\n  {a b : X} [l.NeBot] (ha : Filter.Tendsto f l (nhds a)) (hb : Filter.Tendsto f l (nhds b)) : a = b</code>",
 "273":
 "<code>HilbertCurve.limit_hilbert_continuous : Continuous limit_hilbert_curve</code>",
 "272":
 "<code>Continuous.continuousAt.{u_1, u_2} {X : Type u_1} {Y : Type u_2} [TopologicalSpace X] [TopologicalSpace Y] {f : X ‚Üí Y}\n  {x : X} (h : Continuous f) : ContinuousAt f x</code>",
 "271":
 "<code>StrictMono.tendsto_atTop {œÜ : ‚Ñï ‚Üí ‚Ñï} (h : StrictMono œÜ) : Filter.Tendsto œÜ Filter.atTop Filter.atTop</code>",
 "270":
 "<code>HilbertCurve.limit_hilbert_curve_tendstouniformly :\n  TendstoUniformly normalized_hilbert_curve limit_hilbert_curve Filter.atTop</code><span class=\"sep\"></span><code class=\"docstring\">The real Hilbert curve iterations converges uniformly to the limit Hilbert curve.\n</code>",
 "27":
 "<code>HSub.hSub.{u, v, w} {Œ± : Type u} {Œ≤ : Type v} {Œ≥ : outParam (Type w)} [self : HSub Œ± Œ≤ Œ≥] : Œ± ‚Üí Œ≤ ‚Üí Œ≥</code><span class=\"sep\"></span><code class=\"docstring\">`a - b` computes the difference of `a` and `b`.\nThe meaning of this notation is type-dependent.\n* For natural numbers, this operator saturates at 0: `a - b = 0` when `a ‚â§ b`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `-` in identifiers is `sub` (when used as a binary operator).</code>",
 "269":
 "<code>tendstoUniformly_iff_seq_tendstoUniformly.{u_1, u_2, u_4} {Œ± : Type u_1} {Œ≤ : Type u_2} {Œπ : Type u_4} [UniformSpace Œ≤]\n  {F : Œπ ‚Üí Œ± ‚Üí Œ≤} {f : Œ± ‚Üí Œ≤} {l : Filter Œπ} [l.IsCountablyGenerated] :\n  TendstoUniformly F f l ‚Üî\n    ‚àÄ (u : ‚Ñï ‚Üí Œπ), Filter.Tendsto u Filter.atTop l ‚Üí TendstoUniformly (fun n =&gt; F (u n)) f Filter.atTop</code>",
 "268":
 "<code>TendstoUniformly.tendsto_comp.{u_1, u_2, u_3} {Œ± : Type u_1} {Œ≤ : Type u_2} {Œπ : Type u_3} [TopologicalSpace Œ±]\n  [UniformSpace Œ≤] {F : Œπ ‚Üí Œ± ‚Üí Œ≤} {f : Œ± ‚Üí Œ≤} {x : Œ±} {p : Filter Œπ} {g : Œπ ‚Üí Œ±} (h : TendstoUniformly F f p)\n  (hf : ContinuousAt f x) (hg : Filter.Tendsto g p (nhds x)) : Filter.Tendsto (fun n =&gt; F n (g n)) p (nhds (f x))</code><span class=\"sep\"></span><code class=\"docstring\">If `F‚Çô` tends uniformly to `f`, and `g‚Çô` tends to `x`, then `F‚Çô g‚Çô` tends to `f x`. </code>",
 "267":
 "<code>Filter.Tendsto (fun i =&gt; normalized_hilbert_curve (œÜ i) (f (œÜ i))) Filter.atTop (nhds (limit_hilbert_curve t))</code>",
 "266": "<code>Filter.Tendsto (f ‚àò œÜ) Filter.atTop (nhds t)</code>",
 "265": "<code>‚Ñï ‚Üí ‚Ñù</code>",
 "264":
 "<code class=\"docstring\">`use e‚ÇÅ, e‚ÇÇ, ‚ãØ` is similar to `exists`, but unlike `exists` it is equivalent to applying the tactic\n`refine ‚ü®e‚ÇÅ, e‚ÇÇ, ‚ãØ, ?_, ‚ãØ, ?_‚ü©` with any number of placeholders (rather than just one) and\nthen trying to close goals associated to the placeholders with a configurable discharger (rather\nthan just `try trivial`).\n\nExamples:\n\n```lean\nexample : ‚àÉ x : Nat, x = x := by use 42\n\nexample : ‚àÉ x : Nat, ‚àÉ y : Nat, x = y := by use 42, 42\n\nexample : ‚àÉ x : String √ó String, x.1 = x.2 := by use (\"forty-two\", \"forty-two\")\n```\n\n`use! e‚ÇÅ, e‚ÇÇ, ‚ãØ` is similar but it applies constructors everywhere rather than just for\ngoals that correspond to the last argument of a constructor. This gives the effect that\nnested constructors are being flattened out, with the supplied values being used along the\nleaves and nodes of the tree of constructors.\nWith `use!` one can feed in each `42` one at a time:\n\n```lean\nexample : ‚àÉ p : Nat √ó Nat, p.1 = p.2 := by use! 42, 42\n\nexample : ‚àÉ p : Nat √ó Nat, p.1 = p.2 := by use! (42, 42)\n```\n\nThe second line makes use of the fact that `use!` tries refining with the argument before\napplying a constructor. Also note that `use`/`use!` by default uses a tactic\ncalled `use_discharger` to discharge goals, so `use! 42` will close the goal in this example since\n`use_discharger` applies `rfl`, which as a consequence solves for the other `Nat` metavariable.\n\nThese tactics take an optional discharger to handle remaining explicit `Prop` constructor arguments.\nBy default it is `use (discharger := try with_reducible use_discharger) e‚ÇÅ, e‚ÇÇ, ‚ãØ`.\nTo turn off the discharger and keep all goals, use `(discharger := skip)`.\nTo allow \"heavy refls\", use `(discharger := try use_discharger)`.\n</code>",
 "263":
 "<code>StrictMono.{u, v} {Œ± : Type u} {Œ≤ : Type v} [Preorder Œ±] [Preorder Œ≤] (f : Œ± ‚Üí Œ≤) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A function `f` is strictly monotone if `a &lt; b` implies `f a &lt; f b`. </code>",
 "262":
 "<code>HilbertCurve.norm_hilbert_inv_bounded (i : ‚Ñï) (x : ‚Ñù √ó ‚Ñù) (xh : x ‚àà Set.Icc 0 1) : norm_hilbert_inv i x xh ‚àà Set.Icc 0 1</code><span class=\"sep\"></span><code class=\"docstring\">Approximate inverse of normal_hilbert_curve i lives in [0, 1]\n</code>",
 "261":
 "<code>IsCompact.tendsto_subseq.{u_1} {X : Type u_1} [TopologicalSpace X] [FirstCountableTopology X] {s : Set X} {x : ‚Ñï ‚Üí X}\n  (hs : IsCompact s) (hx : ‚àÄ (n : ‚Ñï), x n ‚àà s) :\n  ‚àÉ a ‚àà s, ‚àÉ œÜ, StrictMono œÜ ‚àß Filter.Tendsto (x ‚àò œÜ) Filter.atTop (nhds a)</code>",
 "260":
 "<code>Filter.Tendsto ((fun n =&gt; norm_hilbert_inv n x xy) ‚àò œÜ) Filter.atTop (nhds t)</code>",
 "26":
 "<code>HAdd.hAdd.{u, v, w} {Œ± : Type u} {Œ≤ : Type v} {Œ≥ : outParam (Type w)} [self : HAdd Œ± Œ≤ Œ≥] : Œ± ‚Üí Œ≤ ‚Üí Œ≥</code><span class=\"sep\"></span><code class=\"docstring\">`a + b` computes the sum of `a` and `b`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `+` in identifiers is `add`.</code>",
 "259": "<code>StrictMono œÜ</code>",
 "258": "<code>‚Ñï ‚Üí ‚Ñï</code>",
 "257": "<code>t ‚àà Set.Icc 0 1</code>",
 "256":
 "<code class=\"docstring\">The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for\na description of supported patterns.\n\n```lean\nobtain ‚ü®patt‚ü© : type := proof\n```\nis equivalent to\n```lean\nhave h : type := proof\nrcases h with ‚ü®patt‚ü©\n```\n\nIf `‚ü®patt‚ü©` is omitted, `rcases` will try to infer the pattern.\n\nIf `type` is omitted, `:= proof` is required.\n</code>",
 "255": "<code>IsCompact (Set.Icc 0 1)</code>",
 "254":
 "<code>CompactIccSpace.isCompact_Icc.{u_1} {Œ± : Type u_1} {inst‚úù : TopologicalSpace Œ±} {inst‚úù¬π : Preorder Œ±}\n  [self : CompactIccSpace Œ±] {a b : Œ±} : IsCompact (Set.Icc a b)</code><span class=\"sep\"></span><code class=\"docstring\">A closed interval `Set.Icc a b` is a compact set for all `a` and `b`. </code>",
 "253":
 "<code>IsCompact.{u_1} {X : Type u_1} [TopologicalSpace X] (s : Set X) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A set `s` is compact if for every nontrivial filter `f` that contains `s`,\nthere exists `a ‚àà s` such that every set of `f` meets every neighborhood of `a`. </code>",
 "252":
 "<code>Set.image.{u, v} {Œ± : Type u} {Œ≤ : Type v} (f : Œ± ‚Üí Œ≤) (s : Set Œ±) : Set Œ≤</code><span class=\"sep\"></span><code class=\"docstring\">The image of `s : Set Œ±` by `f : Œ± ‚Üí Œ≤`, written `f '' s`, is the set of `b : Œ≤` such that\n`f a = b` for some `a ‚àà s`. </code>",
 "251":
 "<code>Membership.mem.{u, v} {Œ± : outParam (Type u)} {Œ≥ : Type v} [self : Membership Œ± Œ≥] : Œ≥ ‚Üí Œ± ‚Üí Prop</code><span class=\"sep\"></span><code class=\"docstring\">The membership relation `a ‚àà s : Prop` where `a : Œ±`, `s : Œ≥`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `‚àà` in identifiers is `mem`.</code>",
 "250": "<code>x ‚àà Set.Icc 0 1</code>",
 "25":
 "<code>HPow.hPow.{u, v, w} {Œ± : Type u} {Œ≤ : Type v} {Œ≥ : outParam (Type w)} [self : HPow Œ± Œ≤ Œ≥] : Œ± ‚Üí Œ≤ ‚Üí Œ≥</code><span class=\"sep\"></span><code class=\"docstring\">`a ^ b` computes `a` to the power of `b`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `^` in identifiers is `pow`.</code>",
 "249":
 "<code>Set.Icc.{u_1} {Œ± : Type u_1} [Preorder Œ±] (a b : Œ±) : Set Œ±</code><span class=\"sep\"></span><code class=\"docstring\">`Icc a b` is the left-closed right-closed interval $[a, b]$. </code>",
 "248": "<code>HilbertCurve.limit_hilbert_curve (t : ‚Ñù) : ‚Ñù √ó ‚Ñù</code>",
 "247":
 "<code>Set.SurjOn.{u, v} {Œ± : Type u} {Œ≤ : Type v} (f : Œ± ‚Üí Œ≤) (s : Set Œ±) (t : Set Œ≤) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`f` is surjective from `s` to `t` if `t` is contained in the image of `s`. </code>",
 "246":
 "<code>HilbertCurve.limit_hilbert_surj_on : Set.SurjOn limit_hilbert_curve (Set.Icc 0 1) (Set.Icc 0 1)</code>",
 "245":
 "<code>Classical.choose.{u} {Œ± : Sort u} {p : Œ± ‚Üí Prop} (h : ‚àÉ x, p x) : Œ±</code><span class=\"sep\"></span><code class=\"docstring\">Given that there exists an element satisfying `p`, returns one such element.\n\nThis is a straightforward consequence of, and equivalent to, `Classical.choice`.\n\nSee also `choose_spec`, which asserts that the returned value has property `p`.\n</code>",
 "244":
 "<code>limit_hilbert_curve' (t : ‚Ñù) : ‚Ñù √ó ‚Ñù</code><span class=\"sep\"></span><code class=\"docstring\">Name has a ' to avoid name conflicts. </code>",
 "243":
 "<code>HilbertCurve.normal_is_cauchy (t : ‚Ñù) : CauchySeq fun x =&gt; normalized_hilbert_curve x t</code><span class=\"sep\"></span><code class=\"docstring\">The Hilbert curve iterations form a Cauchy sequence at each t.\n</code>",
 "242":
 "<code>CauchySeq.{u, v} {Œ± : Type u} {Œ≤ : Type v} [uniformSpace : UniformSpace Œ±] [Preorder Œ≤] (u : Œ≤ ‚Üí Œ±) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">Cauchy sequences. Usually defined on ‚Ñï, but often it is also useful to say that a function\ndefined on ‚Ñù is Cauchy at +‚àû to deduce convergence. Therefore, we define it in a type class that\nis general enough to cover both ‚Ñï and ‚Ñù, which are the main motivating examples. </code>",
 "241":
 "<code>cauchySeq_tendsto_of_complete.{u, v} {Œ± : Type u} {Œ≤ : Type v} [uniformSpace : UniformSpace Œ±] [Preorder Œ≤]\n  [CompleteSpace Œ±] {u : Œ≤ ‚Üí Œ±} (H : CauchySeq u) : ‚àÉ x, Filter.Tendsto u Filter.atTop (nhds x)</code><span class=\"sep\"></span><code class=\"docstring\">A Cauchy sequence in a complete space converges </code>",
 "240":
 "<code>nhds.{u_3} {X : Type u_3} [TopologicalSpace X] (x : X) : Filter X</code><span class=\"sep\"></span><code class=\"docstring\">A set is called a neighborhood of `x` if it contains an open set around `x`. The set of all\nneighborhoods of `x` forms a filter, the neighborhood filter at `x`, is here defined as the\ninfimum over the principal filters of all open sets containing `x`. </code>",
 "24":
 "<code>Prod.mk.{u, v} {Œ± : Type u} {Œ≤ : Type v} (fst : Œ±) (snd : Œ≤) : Œ± √ó Œ≤</code><span class=\"sep\"></span><code class=\"docstring\">Constructs a pair. This is usually written `(x, y)` instead of `Prod.mk x y`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `(a, b)` in identifiers is `mk`.</code>",
 "239":
 "<code>Filter.atTop.{u_3} {Œ± : Type u_3} [Preorder Œ±] : Filter Œ±</code><span class=\"sep\"></span><code class=\"docstring\">`atTop` is the filter representing the limit `‚Üí ‚àû` on an ordered set.\nIt is generated by the collection of up-sets `{b | a ‚â§ b}`.\n(The preorder need not have a top element for this to be well defined,\nand indeed is trivial when a top element exists.) </code>",
 "238":
 "<code>Filter.Tendsto.{u_1, u_2} {Œ± : Type u_1} {Œ≤ : Type u_2} (f : Œ± ‚Üí Œ≤) (l‚ÇÅ : Filter Œ±) (l‚ÇÇ : Filter Œ≤) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Filter.Tendsto` is the generic \"limit of a function\" predicate.\n`Tendsto f l‚ÇÅ l‚ÇÇ` asserts that for every `l‚ÇÇ` neighborhood `a`,\nthe `f`-preimage of `a` is an `l‚ÇÅ` neighborhood. </code>",
 "237":
 "<code>HilbertCurve.limit_hilbert_curve_exists (t : ‚Ñù) :\n  ‚àÉ x, Filter.Tendsto (fun x =&gt; normalized_hilbert_curve x t) Filter.atTop (nhds x)</code><span class=\"sep\"></span><code class=\"docstring\">The real Hilbert converges at each point.\n</code>",
 "236":
 "<code>HilbertCurve.norm_hilbert_inv (i : ‚Ñï) (x : ‚Ñù √ó ‚Ñù) (xh : x ‚àà Set.Icc 0 1) : ‚Ñù</code><span class=\"sep\"></span><code class=\"docstring\">Approximate inverse of normal_hilbert_curve i\n</code>",
 "235":
 "<code>HilbertCurve.exists_normal_hilbert_approx_inv (i : ‚Ñï) (x : ‚Ñù √ó ‚Ñù) (xh : x ‚àà Set.Icc 0 1) :\n  ‚àÉ t ‚àà Set.Icc 0 1, dist x (normalized_hilbert_curve i t) ‚â§ (2 ^ i)‚Åª¬π</code><span class=\"sep\"></span><code class=\"docstring\">Each iteration also touches most points.\n</code>",
 "234":
 "<code class=\"docstring\">`linarith` attempts to find a contradiction between hypotheses that are linear (in)equalities.\nEquivalently, it can prove a linear inequality by assuming its negation and proving `False`.\n\nIn theory, `linarith` should prove any goal that is true in the theory of linear arithmetic over\nthe rationals. While there is some special handling for non-dense orders like `Nat` and `Int`,\nthis tactic is not complete for these theories and will not prove every true goal. It will solve\ngoals over arbitrary types that instantiate `LinearOrderedCommRing`.\n\nAn example:\n```lean\nexample (x y z : ‚Ñö) (h1 : 2*x &lt; 3*y) (h2 : -4*x + 2*z &lt; 0)\n        (h3 : 12*y - 4* z &lt; 0) : False := by\n  linarith\n```\n\n`linarith` will use all appropriate hypotheses and the negation of the goal, if applicable.\nDisequality hypotheses require case splitting and are not normally considered\n(see the `splitNe` option below).\n\n`linarith [t1, t2, t3]` will additionally use proof terms `t1, t2, t3`.\n\n`linarith only [h1, h2, h3, t1, t2, t3]` will use only the goal (if relevant), local hypotheses\n`h1`, `h2`, `h3`, and proofs `t1`, `t2`, `t3`. It will ignore the rest of the local context.\n\n`linarith!` will use a stronger reducibility setting to try to identify atoms. For example,\n```lean\nexample (x : ‚Ñö) : id x ‚â• x := by\n  linarith\n```\nwill fail, because `linarith` will not identify `x` and `id x`. `linarith!` will.\nThis can sometimes be expensive.\n\n`linarith (config := { .. })` takes a config object with five\noptional arguments:\n* `discharger` specifies a tactic to be used for reducing an algebraic equation in the\n  proof stage. The default is `ring`. Other options include `simp` for basic\n  problems.\n* `transparency` controls how hard `linarith` will try to match atoms to each other. By default\n  it will only unfold `reducible` definitions.\n* If `splitHypotheses` is true, `linarith` will split conjunctions in the context into separate\n  hypotheses.\n* If `splitNe` is `true`, `linarith` will case split on disequality hypotheses.\n  For a given `x ‚â† y` hypothesis, `linarith` is run with both `x &lt; y` and `x &gt; y`,\n  and so this runs linarith exponentially many times with respect to the number of\n  disequality hypotheses. (`false` by default.)\n* If `exfalso` is `false`, `linarith` will fail when the goal is neither an inequality nor `False`.\n  (`true` by default.)\n* `restrict_type` (not yet implemented in mathlib4)\n  will only use hypotheses that are inequalities over `tp`. This is useful\n  if you have e.g. both integer and rational valued inequalities in the local context, which can\n  sometimes confuse the tactic.\n\nA variant, `nlinarith`, does some basic preprocessing to handle some nonlinear goals.\n\nThe option `set_option trace.linarith true` will trace certain intermediate stages of the `linarith`\nroutine.\n</code>",
 "233":
 "<code class=\"docstring\">Tactic for evaluating expressions in *commutative* (semi)rings, allowing for variables in the\nexponent. If the goal is not appropriate for `ring` (e.g. not an equality) `ring_nf` will be\nsuggested.\n\n* `ring!` will use a more aggressive reducibility setting to determine equality of atoms.\n* `ring1` fails if the target is not an equality.\n\nFor example:\n```\nexample (n : ‚Ñï) (m : ‚Ñ§) : 2^(n+1) * m = 2 * 2^n * m := by ring\nexample (a b : ‚Ñ§) (n : ‚Ñï) : (a + b)^(n + 2) = (a^2 + b^2 + a * b + b * a) * (a + b)^n := by ring\nexample (x y : ‚Ñï) : x + id y = y + id x := by ring!\nexample (x : ‚Ñï) (h : x * 2 &gt; 5): x + x &gt; 5 := by ring; assumption -- suggests ring_nf\n```\n</code>",
 "232":
 "<code>HilbertCurve.normal_hilbert_across_dist (i n : ‚Ñï) :\n  dist (normalized_hilbert_curve i (‚Üë(n / 4) / ‚Üë(hilbert_length i)))\n      (normalized_hilbert_curve (i + 1) (‚Üën / ‚Üë(hilbert_length (i + 1)))) ‚â§\n    (2 ^ (i + 1))‚Åª¬π</code><span class=\"sep\"></span><code class=\"docstring\">Each real Hilbert curve iteration divides the previous into smaller\ndeviations only 1/2^(i+1) away from the previous.\n</code>",
 "231": "<code>‚àÄ (n : ‚Ñï), ‚Üë‚Üën = ‚Üën</code>",
 "230":
 "<code>Iff.mpr {a b : Prop} (self : a ‚Üî b) : b ‚Üí a</code><span class=\"sep\"></span><code class=\"docstring\">Modus ponens for if and only if, reversed. If `a ‚Üî b` and `b`, then `a`. </code>",
 "23":
 "<code>Prod.{u, v} (Œ± : Type u) (Œ≤ : Type v) : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">The product type, usually written `Œ± √ó Œ≤`. Product types are also called pair or tuple types.\nElements of this type are pairs in which the first element is an `Œ±` and the second element is a\n`Œ≤`.\n\nProducts nest to the right, so `(x, y, z) : Œ± √ó Œ≤ √ó Œ≥` is equivalent to `(x, (y, z)) : Œ± √ó (Œ≤ √ó Œ≥)`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `√ó` in identifiers is `Prod`.</code>",
 "229": "<code>Int.eq_natCast_toNat {a : ‚Ñ§} : a = ‚Üëa.toNat ‚Üî 0 ‚â§ a</code>",
 "228":
 "<code class=\"docstring\">`refine e` behaves like `exact e`, except that named (`?x`) or unnamed (`?_`)\nholes in `e` that are not solved by unification with the main goal's target type\nare converted into new goals, using the hole's name, if any, as the goal case name.\n</code>",
 "227":
 "<code>‚åät * ‚Üë(hilbert_length i)‚åã = ‚åät * ‚Üë(hilbert_length (i + 1))‚åã / 4</code>",
 "226":
 "<code class=\"docstring\">Normalize numerical expressions. Supports the operations `+` `-` `*` `/` `‚Åª¬π` `^` and `%`\nover numerical types such as `‚Ñï`, `‚Ñ§`, `‚Ñö`, `‚Ñù`, `‚ÑÇ` and some general algebraic types,\nand can prove goals of the form `A = B`, `A ‚â† B`, `A &lt; B` and `A ‚â§ B`, where `A` and `B` are\nnumerical expressions. It also has a relatively simple primality prover.\n</code>",
 "225":
 "<code class=\"docstring\">Tactic solving goals of the form `0 ‚â§ x`, `0 &lt; x` and `x ‚â† 0`.  The tactic works recursively\naccording to the syntax of the expression `x`, if the atoms composing the expression all have\nnumeric lower bounds which can be proved positive/nonnegative/nonzero by `norm_num`.  This tactic\neither closes the goal or fails.\n\nExamples:\n```\nexample {a : ‚Ñ§} (ha : 3 &lt; a) : 0 ‚â§ a ^ 3 + a := by positivity\n\nexample {a : ‚Ñ§} (ha : 1 &lt; a) : 0 &lt; |(3:‚Ñ§) + a| := by positivity\n\nexample {b : ‚Ñ§} : 0 ‚â§ max (-3) (b ^ 2) := by positivity\n```\n</code>",
 "224":
 "<code>HilbertCurve.div_floor_mul_eq_floor (t : ‚Ñù) (n : ‚Ñï) (h : 0 ‚â§ t) (h' : 0 &lt; n) : ‚åät * ‚Üën‚åã / ‚Üën = ‚åät‚åã</code><span class=\"sep\"></span><code class=\"docstring\">If you multiply by n, floor, then integer divide by n, then it is the same as floor.\n</code>",
 "223":
 "<code class=\"docstring\">* `symm` applies to a goal whose target has the form `t ~ u` where `~` is a symmetric relation,\n  that is, a relation which has a symmetry lemma tagged with the attribute [symm].\n  It replaces the target with `u ~ t`.\n* `symm at h` will rewrite a hypothesis `h : t ~ u` to `h : u ~ t`.\n</code>",
 "222":
 "<code>mul_assoc.{u_1} {G : Type u_1} [Semigroup G] (a b c : G) : a * b * c = a * (b * c)</code>",
 "221":
 "<code>Nat.cast_ofNat.{u_1} {R : Type u_1} {n : ‚Ñï} [NatCast R] [n.AtLeastTwo] : ‚Üë(OfNat.ofNat n) = OfNat.ofNat n</code>",
 "220":
 "<code>Nat.cast_mul.{u_1} {Œ± : Type u_1} [NonAssocSemiring Œ±] (m n : ‚Ñï) : ‚Üë(m * n) = ‚Üëm * ‚Üën</code>",
 "22":
 "<code>Nat : Type</code><span class=\"sep\"></span><code class=\"docstring\">The natural numbers, starting at zero.\n\nThis type is special-cased by both the kernel and the compiler, and overridden with an efficient\nimplementation. Both use a fast arbitrary-precision arithmetic library (usually\n[GMP](https://gmplib.org/)); at runtime, `Nat` values that are sufficiently small are unboxed.\n</code>",
 "219":
 "<code>mul_comm.{u_1} {G : Type u_1} [CommMagma G] (a b : G) : a * b = b * a</code>",
 "218": "<code>0 &lt; t</code>",
 "217":
 "<code>not_le.{u_1} {Œ± : Type u_1} [LinearOrder Œ±] {a b : Œ±} : ¬¨a ‚â§ b ‚Üî b &lt; a</code>",
 "216":
 "<code>HilbertCurve.normal_hilbert_start (i : ‚Ñï) : normalized_hilbert_curve i 0 = (0, 0)</code><span class=\"sep\"></span><code class=\"docstring\">Every iteration of the hilbert curve starts at 0 when t = 0.\n</code>",
 "215": "<code>‚àÄ (n : ‚Ñï), ‚Üë‚åät * ‚Üën‚åã / ‚Üën ‚â§ 0</code>",
 "214":
 "<code>HilbertCurve.normalized_hilbert_curve_nonpos (i : ‚Ñï) (t : ‚Ñù) (h : t ‚â§ 0) :\n  normalized_hilbert_curve i t = normalized_hilbert_curve i 0</code><span class=\"sep\"></span><code class=\"docstring\">For t ‚â§ 0, the real hilbert curve is still 0.\n</code>",
 "213":
 "<code>Nat.cast_nonneg.{u_3} {Œ± : Type u_3} [Semiring Œ±] [PartialOrder Œ±] [IsOrderedRing Œ±] (n : ‚Ñï) : 0 ‚â§ ‚Üën</code><span class=\"sep\"></span><code class=\"docstring\">Specialisation of `Nat.cast_nonneg'`, which seems to be easier for Lean to use. </code>",
 "212":
 "<code>mul_nonpos_of_nonpos_of_nonneg.{u_1} {Œ± : Type u_1} [MulZeroClass Œ±] {a b : Œ±} [Preorder Œ±] [MulPosMono Œ±] (ha : a ‚â§ 0)\n  (hb : 0 ‚â§ b) : a * b ‚â§ 0</code>",
 "211":
 "<code>Int.floor_nonpos.{u_2} {Œ± : Type u_2} [Ring Œ±] [LinearOrder Œ±] [FloorRing Œ±] {a : Œ±} [IsStrictOrderedRing Œ±]\n  (ha : a ‚â§ 0) : ‚åäa‚åã ‚â§ 0</code>",
 "210":
 "<code class=\"docstring\">The `norm_cast` family of tactics is used to normalize certain coercions (*casts*) in expressions.\n- `norm_cast` normalizes casts in the target.\n- `norm_cast at h` normalizes casts in hypothesis `h`.\n\nThe tactic is basically a version of `simp` with a specific set of lemmas to move casts\nupwards in the expression.\nTherefore even in situations where non-terminal `simp` calls are discouraged (because of fragility),\n`norm_cast` is considered to be safe.\nIt also has special handling of numerals.\n\nFor instance, given an assumption\n```lean\na b : ‚Ñ§\nh : ‚Üëa + ‚Üëb &lt; (10 : ‚Ñö)\n```\nwriting `norm_cast at h` will turn `h` into\n```lean\nh : a + b &lt; 10\n```\n\nThere are also variants of basic tactics that use `norm_cast` to normalize expressions during\ntheir operation, to make them more flexible about the expressions they accept\n(we say that it is a tactic *modulo* the effects of `norm_cast`):\n- `exact_mod_cast` for `exact` and `apply_mod_cast` for `apply`.\n  Writing `exact_mod_cast h` and `apply_mod_cast h` will normalize casts\n  in the goal and `h` before using `exact h` or `apply h`.\n- `rw_mod_cast` for `rw`. It applies `norm_cast` between rewrites.\n- `assumption_mod_cast` for `assumption`.\n  This is effectively `norm_cast at *; assumption`, but more efficient.\n  It normalizes casts in the goal and, for every hypothesis `h` in the context,\n  it will try to normalize casts in `h` and use `exact h`.\n\nSee also `push_cast`, which moves casts inwards rather than lifting them outwards.\n</code>",
 "21": "<code>Ring R</code>",
 "209":
 "<code>div_nonpos_of_nonpos_of_nonneg.{u_3} {G‚ÇÄ : Type u_3} [GroupWithZero G‚ÇÄ] [PartialOrder G‚ÇÄ] [MulPosReflectLT G‚ÇÄ]\n  {a b : G‚ÇÄ} (ha : a ‚â§ 0) (hb : 0 ‚â§ b) : a / b ‚â§ 0</code>",
 "208":
 "<code>Not (a : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Not p`, or `¬¨p`, is the negation of `p`. It is defined to be `p ‚Üí False`,\nso if your goal is `¬¨p` you can use `intro h` to turn the goal into\n`h : p ‚ä¢ False`, and if you have `hn : ¬¨p` and `h : p` then `hn h : False`\nand `(hn h).elim` will prove anything.\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `¬¨` in identifiers is `not`.</code>",
 "207": "<code>¬¨t ‚â§ 0</code>",
 "206": "<code>t ‚â§ 0</code>",
 "205":
 "<code class=\"docstring\">`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬¨ p` in the second branch.\n</code>",
 "204":
 "<code>dist (normalized_hilbert_curve i (‚Üë‚åät * ‚Üë(hilbert_length i)‚åã / ‚Üë(hilbert_length i)))\n    (normalized_hilbert_curve (i + 1) (‚Üë‚åät * ‚Üë(hilbert_length (i + 1))‚åã / ‚Üë(hilbert_length (i + 1)))) ‚â§\n  (2 ^ (i + 1))‚Åª¬π</code>",
 "203":
 "<code>dist_comm.{u} {Œ± : Type u} [PseudoMetricSpace Œ±] (x y : Œ±) : dist x y = dist y x</code>",
 "202":
 "<code>dist (normalized_hilbert_curve (i + 1) (‚Üë‚åät * ‚Üë(hilbert_length (i + 1))‚åã / ‚Üë(hilbert_length (i + 1))))\n    (normalized_hilbert_curve (i + 1) t) ‚â§\n  (2 ^ (i + 1))‚Åª¬π</code>",
 "201":
 "<code>HilbertCurve.normal_hilbert_dist (i : ‚Ñï) (t : ‚Ñù) :\n  dist (normalized_hilbert_curve i t) (normalized_hilbert_curve i (‚Üë‚åät * ‚Üë(hilbert_length i)‚åã / ‚Üë(hilbert_length i))) ‚â§\n    (2 ^ i)‚Åª¬π</code><span class=\"sep\"></span><code class=\"docstring\">Each point on a real Hilbert curve iteration is close to an interpolated point.\n</code>",
 "200":
 "<code>dist (normalized_hilbert_curve i t) (normalized_hilbert_curve i (‚Üë‚åät * ‚Üë(hilbert_length i)‚åã / ‚Üë(hilbert_length i))) ‚â§\n  (2 ^ i)‚Åª¬π</code>",
 "20":
 "<code class=\"docstring\">A type universe. `Type ‚â° Type 0`, `Type u ‚â° Sort (u + 1)`. </code>",
 "2": "<code>T0_nat : ‚Ñï √ó ‚Ñï ‚Üí ‚Ñï √ó ‚Ñï</code>",
 "199":
 "<code>dist_triangle4.{u} {Œ± : Type u} [PseudoMetricSpace Œ±] (x y z w : Œ±) : dist x w ‚â§ dist x y + dist y z + dist z w</code>",
 "198":
 "<code>Dist.dist.{u_3} {Œ± : Type u_3} [self : Dist Œ±] : Œ± ‚Üí Œ± ‚Üí ‚Ñù</code><span class=\"sep\"></span><code class=\"docstring\">Distance between two points </code>",
 "197":
 "<code>HilbertCurve.normal_subdivision_size (i : ‚Ñï) (t : ‚Ñù) :\n  dist (normalized_hilbert_curve i t) (normalized_hilbert_curve (i + 1) t) ‚â§ 2 * (2 ^ i)‚Åª¬π</code><span class=\"sep\"></span><code class=\"docstring\">The real Hilbert curve only moves 1 / 2^(i-1) each iteration for each t.\n</code>",
 "196":
 "<code>Int.floor.{u_2} {Œ± : Type u_2} [Ring Œ±] [LinearOrder Œ±] [FloorRing Œ±] : Œ± ‚Üí ‚Ñ§</code><span class=\"sep\"></span><code class=\"docstring\">`Int.floor a` is the greatest integer `z` such that `z ‚â§ a`. It is denoted with `‚åäa‚åã`. </code>",
 "195": "<code>0 &lt; n</code>",
 "194": "<code>0 ‚â§ t</code>",
 "193":
 "<code>div_floor_mul_eq_floor (t : ‚Ñù) (n : ‚Ñï) (h : 0 ‚â§ t) (h' : 0 &lt; n) : ‚åät * ‚Üën‚åã / ‚Üën = ‚åät‚åã</code><span class=\"sep\"></span><code class=\"docstring\">If you multiply by n, floor, then integer divide by n, then it is the same as floor.\n</code>",
 "192":
 "<code>continuous_mul_right.{u_3} {M : Type u_3} [TopologicalSpace M] [Mul M] [ContinuousMul M] (a : M) :\n  Continuous fun b =&gt; b * a</code>",
 "191":
 "<code>Continuous.comp.{u_1, u_2, u_3} {X : Type u_1} {Y : Type u_2} {Z : Type u_3} [TopologicalSpace X] [TopologicalSpace Y]\n  [TopologicalSpace Z] {f : X ‚Üí Y} {g : Y ‚Üí Z} (hg : Continuous g) (hf : Continuous f) : Continuous (g ‚àò f)</code>",
 "190": "<code>Continuous (interpolate_points f)</code>",
 "19":
 "<code class=\"docstring\">`by tac` constructs a term of the expected type by running the tactic(s) `tac`. </code>",
 "189":
 "<code>interpolate_is_continuous (f : ‚Ñ§ ‚Üí ‚Ñù √ó ‚Ñù) : Continuous (interpolate_points f)</code><span class=\"sep\"></span><code class=\"docstring\">Interpolation is continuous\n</code>",
 "188":
 "<code>Int : Type</code><span class=\"sep\"></span><code class=\"docstring\">The integers.\n\nThis type is special-cased by the compiler and overridden with an efficient implementation. The\nruntime has a special representation for `Int` that stores ‚Äúsmall‚Äù signed numbers directly, while\nlarger numbers use a fast arbitrary-precision arithmetic library (usually\n[GMP](https://gmplib.org/)). A ‚Äúsmall number‚Äù is an integer that can be encoded with one fewer bits\nthan the platform's pointer size (i.e. 63 bits on 64-bit architectures and 31 bits on 32-bit\narchitectures).\n</code>",
 "187":
 "<code>f = ‚áë(scale (2 ^ i)‚Åª¬π) ‚àò (fun x =&gt; (‚Üëx.1, ‚Üëx.2)) ‚àò hilbert_curve i ‚àò fun x =&gt; x.toNat</code>",
 "186":
 "<code>Inv.inv.{u} {Œ± : Type u} [self : Inv Œ±] : Œ± ‚Üí Œ±</code><span class=\"sep\"></span><code class=\"docstring\">`a‚Åª¬π` computes the inverse of `a`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `‚Åª¬π` in identifiers is `inv`.</code>",
 "185":
 "<code>HilbertCurve.scale (s : ‚Ñù) : ‚Ñù √ó ‚Ñù ‚ÜíL[‚Ñù] ‚Ñù √ó ‚Ñù</code><span class=\"sep\"></span><code class=\"docstring\">scale is smul as a LinearMap\n</code>",
 "184":
 "<code>Function.comp.{u, v, w} {Œ± : Sort u} {Œ≤ : Sort v} {Œ¥ : Sort w} (f : Œ≤ ‚Üí Œ¥) (g : Œ± ‚Üí Œ≤) : Œ± ‚Üí Œ¥</code><span class=\"sep\"></span><code class=\"docstring\">Function composition, usually written with the infix operator `‚àò`. A new function is created from\ntwo existing functions, where one function's output is used as input to the other.\n\nExamples:\n * `Function.comp List.reverse (List.drop 2) [3, 2, 4, 1] = [1, 4]`\n * `(List.reverse ‚àò List.drop 2) [3, 2, 4, 1] = [1, 4]`\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `‚àò` in identifiers is `comp`.</code>",
 "183":
 "<code>HilbertCurve.normalized_hilbert_curve (i : ‚Ñï) : ‚Ñù ‚Üí ‚Ñù √ó ‚Ñù</code><span class=\"sep\"></span><code class=\"docstring\">An iteration of the Hilbert curve as ‚Ñù ‚Üí ‚Ñù √ó ‚Ñù interpolated\nand scaled to [0, 1] √ó [0, 1].\n</code>",
 "182":
 "<code>Continuous.{u, v} {X : Type u} {Y : Type v} [TopologicalSpace X] [TopologicalSpace Y] (f : X ‚Üí Y) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A function between topological spaces is continuous if the preimage\nof every open set is open. Registered as a structure to make sure it is not unfolded by Lean. </code>",
 "181":
 "<code>HilbertCurve.normal_hilbert_curve_continuous (i : ‚Ñï) : Continuous (normalized_hilbert_curve i)</code><span class=\"sep\"></span><code class=\"docstring\">Each real Hilbert curve is continuous.\n</code>",
 "180":
 "<code>Int.toNat : ‚Ñ§ ‚Üí ‚Ñï</code><span class=\"sep\"></span><code class=\"docstring\">Converts an integer into a natural number. Negative numbers are converted to `0`.\n\nExamples:\n* `(7 : Int).toNat = 7`\n* `(0 : Int).toNat = 0`\n* `(-7 : Int).toNat = 0`\n</code>",
 "18":
 "<code>‚àÄ (p v : R √ó R),\n  (2 ^ (i + 1) - 1, 2 ^ i - 1) - (v +·µ• p).swap = (-HilbertCurve.T0) v +·µ• (2 ^ (i + 1) - 1, 2 ^ i - 1) - p.swap</code>",
 "179":
 "<code>normalized_hilbert_curve (i : ‚Ñï) : ‚Ñù ‚Üí ‚Ñù √ó ‚Ñù</code><span class=\"sep\"></span><code class=\"docstring\">An iteration of the Hilbert curve as ‚Ñù ‚Üí ‚Ñù √ó ‚Ñù interpolated\nand scaled to [0, 1] √ó [0, 1].\n</code>",
 "178":
 "<code>True : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`True` is a proposition and has only an introduction rule, `True.intro : True`.\nIn other words, `True` is simply true, and has a canonical proof, `True.intro`\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n</code>",
 "177":
 "<code class=\"docstring\">Simplification tactic for expressions in the language of commutative (semi)rings,\nwhich rewrites all ring expressions into a normal form.\n* `ring_nf!` will use a more aggressive reducibility setting to identify atoms.\n* `ring_nf (config := cfg)` allows for additional configuration:\n  * `red`: the reducibility setting (overridden by `!`)\n  * `zetaDelta`: if true, local let variables can be unfolded (overridden by `!`)\n  * `recursive`: if true, `ring_nf` will also recurse into atoms\n* `ring_nf` works as both a tactic and a conv tactic.\n  In tactic mode, `ring_nf at h` can be used to rewrite in a hypothesis.\n\nThis can be used non-terminally to normalize ring expressions in the goal such as\n`‚ä¢ P (x + x + x)` ~&gt; `‚ä¢ P (x * 3)`, as well as being able to prove some equations that\n`ring` cannot because they involve ring reasoning inside a subterm, such as\n`sin (x + y) + sin (y + x) = 2 * sin (x + y)`.\n</code>",
 "176":
 "<code>RingHom.id.{u_5} (Œ± : Type u_5) [NonAssocSemiring Œ±] : Œ± ‚Üí+* Œ±</code><span class=\"sep\"></span><code class=\"docstring\">The identity ring homomorphism from a semiring to itself. </code>",
 "175":
 "<code>‚àÄ (m : ‚Ñù) (x : ‚Ñù √ó ‚Ñù), s ‚Ä¢ m ‚Ä¢ x = (RingHom.id ‚Ñù) m ‚Ä¢ s ‚Ä¢ x</code><span class=\"sep\"></span><code class=\"docstring\">The proposition that the function commutes with the actions. </code>",
 "174":
 "<code>HSMul.hSMul.{u, v, w} {Œ± : Type u} {Œ≤ : Type v} {Œ≥ : outParam (Type w)} [self : HSMul Œ± Œ≤ Œ≥] : Œ± ‚Üí Œ≤ ‚Üí Œ≥</code><span class=\"sep\"></span><code class=\"docstring\">`a ‚Ä¢ b` computes the product of `a` and `b`.\nThe meaning of this notation is type-dependent, but it is intended to be used for left actions. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `‚Ä¢` in identifiers is `smul`.</code>",
 "173":
 "<code>Real : Type</code><span class=\"sep\"></span><code class=\"docstring\">The type `‚Ñù` of real numbers constructed as equivalence classes of Cauchy sequences of rational\nnumbers. </code>",
 "172":
 "<code>‚àÄ (x y : ‚Ñù √ó ‚Ñù), s ‚Ä¢ (x + y) = s ‚Ä¢ x + s ‚Ä¢ y</code><span class=\"sep\"></span><code class=\"docstring\">The proposition that the function preserves addition </code>",
 "171": "<code>‚Ñù √ó ‚Ñù</code>",
 "170":
 "<code>‚Ñù √ó ‚Ñù ‚Üí ‚Ñù √ó ‚Ñù</code><span class=\"sep\"></span><code class=\"docstring\">The underlying function </code>",
 "17":
 "<code>HilbertCurve.T0.{u_1} {R : Type u_1} [Ring R] : R √ó R ‚Üí‚Çó[R] R √ó R</code>",
 "169":
 "<code>LinearMap.toContinuousLinearMap.{u, v, x} {ùïú : Type u} [hnorm : NontriviallyNormedField ùïú] {E : Type v} [AddCommGroup E]\n  [Module ùïú E] [TopologicalSpace E] [IsTopologicalAddGroup E] [ContinuousSMul ùïú E] {F' : Type x} [AddCommGroup F']\n  [Module ùïú F'] [TopologicalSpace F'] [IsTopologicalAddGroup F'] [ContinuousSMul ùïú F'] [CompleteSpace ùïú] [T2Space E]\n  [FiniteDimensional ùïú E] : (E ‚Üí‚Çó[ùïú] F') ‚âÉ‚Çó[ùïú] E ‚ÜíL[ùïú] F'</code><span class=\"sep\"></span><code class=\"docstring\">The continuous linear map induced by a linear map on a finite dimensional space </code>",
 "168":
 "<code>scale (s : ‚Ñù) : ‚Ñù √ó ‚Ñù ‚ÜíL[‚Ñù] ‚Ñù √ó ‚Ñù</code><span class=\"sep\"></span><code class=\"docstring\">scale is smul as a LinearMap\n</code>",
 "167":
 "<code>AffineMap.lineMap.{u_1, u_2, u_3} {k : Type u_1} {V1 : Type u_2} {P1 : Type u_3} [Ring k] [AddCommGroup V1]\n  [Module k V1] [AddTorsor V1 P1] (p‚ÇÄ p‚ÇÅ : P1) : k ‚Üí·µÉ[k] P1</code><span class=\"sep\"></span><code class=\"docstring\">The affine map from `k` to `P1` sending `0` to `p‚ÇÄ` and `1` to `p‚ÇÅ`. </code>",
 "166": "<code>‚Ñ§</code>",
 "165": "<code>‚Ñù</code>",
 "164": "<code>‚Ñ§ ‚Üí ‚Ñù √ó ‚Ñù</code>",
 "163": "<code>interpolate_points (f : ‚Ñ§ ‚Üí ‚Ñù √ó ‚Ñù) (t : ‚Ñù) : ‚Ñù √ó ‚Ñù</code>",
 "162": "<code>IsStrictOrderedRing Œ±</code>",
 "161": "<code>Ring Œ±</code>",
 "160": "<code>PartialOrder Œ±</code>",
 "16": "<code>R √ó R ‚Üí‚Çó[R] R √ó R</code>",
 "159":
 "<code>IsOrderedRing.{u_1} (R : Type u_1) [Semiring R] [PartialOrder R] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">An ordered semiring is a semiring with a partial order such that addition is monotone and\nmultiplication by a nonnegative number is monotone. </code>",
 "158":
 "<code>IsStrictOrderedRing.{u_1} (R : Type u_1) [Semiring R] [PartialOrder R] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A strict ordered semiring is a nontrivial semiring with a partial order such that addition is\nstrictly monotone and multiplication by a positive number is strictly monotone. </code>",
 "157":
 "<code>PartialOrder.{u_2} (Œ± : Type u_2) : Type u_2</code><span class=\"sep\"></span><code class=\"docstring\">A partial order is a reflexive, transitive, antisymmetric relation `‚â§`. </code>",
 "156": "<code>Type</code>",
 "155":
 "<code>‚Ñï √ó ‚Ñï ‚Üí R √ó R</code><span class=\"sep\"></span><code class=\"docstring\">Coerces a value of type `Œ±` to type `Œ≤`. Accessible by the notation `‚Üëx`,\nor by double type ascription `((x : Œ±) : Œ≤)`. </code>",
 "154":
 "<code>Coe.{u, v} (Œ± : semiOutParam (Sort u)) (Œ≤ : Sort v) : Sort (max (max 1 u) v)</code><span class=\"sep\"></span><code class=\"docstring\">`Coe Œ± Œ≤` is the typeclass for coercions from `Œ±` to `Œ≤`. It can be transitively\nchained with other `Coe` instances, and coercion is automatically used when\n`x` has type `Œ±` but it is used in a context where `Œ≤` is expected.\nYou can use the `‚Üëx` operator to explicitly trigger coercion.\n</code>",
 "153":
 "<code class=\"docstring\">The `@[coe]` attribute on a function (which should also appear in a\n`instance : Coe A B := ‚ü®myFn‚ü©` declaration) allows the delaborator to show\napplications of this function as `‚Üë` when printing expressions.\n</code>",
 "152":
 "<code>NtimesN.toRtimesR.{u_1} {R : Type u_1} [Ring R] : ‚Ñï √ó ‚Ñï ‚Üí R √ó R</code>",
 "151":
 "<code>pow_add.{u_2} {M : Type u_2} [Monoid M] (a : M) (m n : ‚Ñï) : a ^ (m + n) = a ^ m * a ^ n</code>",
 "150":
 "<code class=\"docstring\">If the main goal's target type is an inductive type, `constructor` solves it with\nthe first matching constructor, or else fails.\n</code>",
 "15": "<code>R</code>",
 "149": "<code>mn2.2 ‚â§ 2 * mn1.2 + 1</code>",
 "148": "<code>mn2.1 ‚â§ 2 * mn1.1 + 1</code>",
 "147": "<code>2 * mn1.2 ‚â§ mn2.2</code>",
 "146": "<code>2 * mn1.1 ‚â§ mn2.1</code>",
 "145": "<code>mn2 ‚â§ 2 * mn1 + 1</code>",
 "144": "<code>2 * mn1 ‚â§ mn2</code>",
 "143":
 "<code class=\"docstring\">Introduces one or more hypotheses, optionally naming and/or pattern-matching them.\nFor each hypothesis to be introduced, the remaining main goal's target type must\nbe a `let` or function type.\n\n* `intro` by itself introduces one anonymous hypothesis, which can be accessed\n  by e.g. `assumption`.\n* `intro x y` introduces two hypotheses and names them. Individual hypotheses\n  can be anonymized via `_`, or matched against a pattern:\n  ```lean\n  -- ... ‚ä¢ Œ± √ó Œ≤ ‚Üí ...\n  intro (a, b)\n  -- ..., a : Œ±, b : Œ≤ ‚ä¢ ...\n  ```\n* Alternatively, `intro` can be combined with pattern matching much like `fun`:\n  ```lean\n  intro\n  | n + 1, 0 =&gt; tac\n  | ...\n  ```\n</code>",
 "142":
 "<code>T1_within_square (i : ‚Ñï) (mn1 mn2 : ‚Ñï √ó ‚Ñï) : within_square mn1 mn2 ‚Üí within_square (T1_nat i mn1) (T1_nat (i + 1) mn2)</code>",
 "141":
 "<code class=\"docstring\">The universe of propositions. `Prop ‚â° Sort 0`.\n\nEvery proposition is propositionally equal to either `True` or `False`. </code>",
 "140": "<code>within_square (a b : ‚Ñï √ó ‚Ñï) : Prop</code>",
 "14": "<code>R √ó R</code>",
 "139":
 "<code>HDiv.hDiv.{u, v, w} {Œ± : Type u} {Œ≤ : Type v} {Œ≥ : outParam (Type w)} [self : HDiv Œ± Œ≤ Œ≥] : Œ± ‚Üí Œ≤ ‚Üí Œ≥</code><span class=\"sep\"></span><code class=\"docstring\">`a / b` computes the result of dividing `a` by `b`.\nThe meaning of this notation is type-dependent.\n* For most types like `Nat`, `Int`, `Rat`, `Real`, `a / 0` is defined to be `0`.\n* For `Nat`, `a / b` rounds downwards.\n* For `Int`, `a / b` rounds downwards if `b` is positive or upwards if `b` is negative.\n  It is implemented as `Int.ediv`, the unique function satisfying\n  `a % b + b * (a / b) = a` and `0 ‚â§ a % b &lt; natAbs b` for `b ‚â† 0`.\n  Other rounding conventions are available using the functions\n  `Int.fdiv` (floor rounding) and `Int.tdiv` (truncation rounding).\n* For `Float`, `a / 0` follows the IEEE 754 semantics for division,\n  usually resulting in `inf` or `nan`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `/` in identifiers is `div`.</code>",
 "138":
 "<code>subdivision_size (i n : ‚Ñï) :\n  2 * hilbert_curve i (n / 4) ‚â§ hilbert_curve (i + 1) n ‚àß hilbert_curve (i + 1) n ‚â§ 2 * hilbert_curve i (n / 4) + 1</code>",
 "137":
 "<code>le_trans.{u_1} {Œ± : Type u_1} [Preorder Œ±] {a b c : Œ±} : a ‚â§ b ‚Üí b ‚â§ c ‚Üí a ‚â§ c</code><span class=\"sep\"></span><code class=\"docstring\">The relation `‚â§` on a preorder is transitive. </code>",
 "136": "<code>n &lt; 4 * hilbert_length i</code>",
 "135":
 "<code>HilbertCurve.hilbert_length_succ (i : ‚Ñï) : hilbert_length (i + 1) = 4 * hilbert_length i</code><span class=\"sep\"></span><code class=\"docstring\">An inductive characterization of hilbert_length\n</code>",
 "134": "<code>3 * hilbert_length i ‚â§ n</code>",
 "133":
 "<code>HilbertCurve.bottom_right_eq (i n : ‚Ñï) : get_quadrant i n = Quadrant.BOTTOM_RIGHT ‚Üî 3 * hilbert_length i ‚â§ n</code>",
 "132":
 "<code>HilbertCurve.T3_inv_of_T3_nat (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) (h1 : mn.1 ‚â§ 2 ^ i - 1) (h2 : mn.2 ‚â§ 2 ^ (i + 1) - 1) :\n  T3_inv_nat i (T3_nat i mn) = mn</code>",
 "131":
 "<code>HilbertCurve.hilbert_curve_size (i n : ‚Ñï) : hilbert_curve i n ‚â§ (2 ^ i - 1, 2 ^ i - 1)</code>",
 "130":
 "<code>hilbert_curve i (n - 3 * hilbert_length i) ‚â§ (2 ^ i - 1, 2 ^ i - 1)</code>",
 "13": "<code>R √ó R ‚Üí R √ó R</code>",
 "129": "<code>2 * hilbert_length i ‚â§ n ‚àß n &lt; 3 * hilbert_length i</code>",
 "128":
 "<code>HilbertCurve.top_right_eq (i n : ‚Ñï) :\n  get_quadrant i n = Quadrant.TOP_RIGHT ‚Üî 2 * hilbert_length i ‚â§ n ‚àß n &lt; 3 * hilbert_length i</code>",
 "127":
 "<code>HilbertCurve.T2_inv_of_T2_nat (i : ‚Ñï) : Function.LeftInverse (T2_inv_nat i) (T2_nat i)</code>",
 "126":
 "<code class=\"docstring\">The `omega` tactic, for resolving integer and natural linear arithmetic problems.\n\nIt is not yet a full decision procedure (no \"dark\" or \"grey\" shadows),\nbut should be effective on many problems.\n\nWe handle hypotheses of the form `x = y`, `x &lt; y`, `x ‚â§ y`, and `k ‚à£ x` for `x y` in `Nat` or `Int`\n(and `k` a literal), along with negations of these statements.\n\nWe decompose the sides of the inequalities as linear combinations of atoms.\n\nIf we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables\nand the relevant inequalities.\n\nOn the first pass, we do not perform case splits on natural subtraction.\nIf `omega` fails, we recursively perform a case split on\na natural subtraction appearing in a hypothesis, and try again.\n\nThe options\n```\nomega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax\n```\ncan be used to:\n* `splitDisjunctions`: split any disjunctions found in the context,\n  if the problem is not otherwise solvable.\n* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ‚â§ b` if necessary.\n* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ‚â§ a` if necessary.\n* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ‚à® min a b = b`\nCurrently, all of these are on by default.\n</code>",
 "125":
 "<code>And (a b : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`And a b`, or `a ‚àß b`, is the conjunction of propositions. It can be\nconstructed and destructed like a pair: if `ha : a` and `hb : b` then\n`‚ü®ha, hb‚ü© : a ‚àß b`, and if `h : a ‚àß b` then `h.left : a` and `h.right : b`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `‚àß` in identifiers is `and`.\n\n * The recommended spelling of `/\\` in identifiers is `and` (prefer `‚àß` over `/\\`).</code>",
 "124": "<code>hilbert_length i ‚â§ n ‚àß n &lt; 2 * hilbert_length i</code>",
 "123":
 "<code>HilbertCurve.top_left_eq (i n : ‚Ñï) :\n  get_quadrant i n = Quadrant.TOP_LEFT ‚Üî hilbert_length i ‚â§ n ‚àß n &lt; 2 * hilbert_length i</code>",
 "122":
 "<code>HilbertCurve.T1_inv_of_T1_nat (i : ‚Ñï) : Function.LeftInverse (T1_inv_nat i) (T1_nat i)</code>",
 "121":
 "<code>Eq.symm.{u} {Œ± : Sort u} {a b : Œ±} (h : a = b) : b = a</code><span class=\"sep\"></span><code class=\"docstring\">Equality is symmetric: if `a = b` then `b = a`.\n\nBecause this is in the `Eq` namespace, if you have a variable `h : a = b`,\n`h.symm` can be used as shorthand for `Eq.symm h` as a proof of `b = a`.\n\nFor more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)\n</code>",
 "120":
 "<code>Iff.mp {a b : Prop} (self : a ‚Üî b) : a ‚Üí b</code><span class=\"sep\"></span><code class=\"docstring\">Modus ponens for if and only if. If `a ‚Üî b` and `a`, then `b`. </code>",
 "12":
 "<code>T3.{u_1} {R : Type u_1} [Ring R] (i : ‚Ñï) : R √ó R ‚Üí·µÉ[R] R √ó R</code>",
 "119":
 "<code>HilbertCurve.bottom_left_eq (i n : ‚Ñï) : get_quadrant i n = Quadrant.BOTTOM_LEFT ‚Üî n &lt; hilbert_length i</code>",
 "118":
 "<code class=\"docstring\">`exact e` closes the main goal if its target type matches that of `e`.\n</code>",
 "117":
 "<code>HilbertCurve.T0_involutive.{u_2} {R : Type u_2} [Ring R] : Function.Involutive ‚áëT0</code>",
 "116": "<code>HilbertCurve.T3_nat (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) : ‚Ñï √ó ‚Ñï</code>",
 "115": "<code>HilbertCurve.T2_nat (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) : ‚Ñï √ó ‚Ñï</code>",
 "114": "<code>HilbertCurve.T1_nat (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) : ‚Ñï √ó ‚Ñï</code>",
 "113":
 "<code class=\"docstring\">The `dsimp` tactic is the definitional simplifier. It is similar to `simp` but only\napplies theorems that hold by reflexivity. Thus, the result is guaranteed to be\ndefinitionally equal to the input.\n</code>",
 "112": "<code>Quadrant.BOTTOM_RIGHT = get_quadrant i n</code>",
 "111":
 "<code>get_quadrant' i (hilbert_curve (i + 1) n) = Quadrant.BOTTOM_RIGHT</code>",
 "110": "<code>Quadrant.TOP_RIGHT = get_quadrant i n</code>",
 "11":
 "<code>Ring.{u} (R : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A `Ring` is a `Semiring` with negation making it an additive group. </code>",
 "109":
 "<code>get_quadrant' i (hilbert_curve (i + 1) n) = Quadrant.TOP_RIGHT</code>",
 "108": "<code>Quadrant.TOP_LEFT = get_quadrant i n</code>",
 "107":
 "<code>get_quadrant' i (hilbert_curve (i + 1) n) = Quadrant.TOP_LEFT</code>",
 "106": "<code>Quadrant.BOTTOM_LEFT = get_quadrant i n</code>",
 "105":
 "<code>get_quadrant' i (hilbert_curve (i + 1) n) = Quadrant.BOTTOM_LEFT</code>",
 "104":
 "<code class=\"docstring\">`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to\ndestructure hypotheses or expressions composed of inductive types like `h1 : a ‚àß b ‚àß c ‚à® d` or\n`h2 : ‚àÉ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ‚ü®ha, hb, hc‚ü© | hd` or\n`rcases h2 with ‚ü®x, y, _ | ‚ü®z, hxz, hzy‚ü©‚ü©` for these examples.\n\nEach element of an `rcases` pattern is matched against a particular local hypothesis (most of which\nare generated during the execution of `rcases` and represent individual elements destructured from\nthe input expression). An `rcases` pattern has the following grammar:\n\n* A name like `x`, which names the active hypothesis as `x`.\n* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the\n  hypothesis).\n* A hyphen `-`, which clears the active hypothesis and any dependents.\n* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the\n  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).\n* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it\n  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)\n* A tuple pattern `‚ü®p1, p2, p3‚ü©`, which matches a constructor with many arguments, or a series\n  of nested conjunctions or existentials. For example if the active hypothesis is `a ‚àß b ‚àß c`,\n  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`\n  and so on.\n* A `@` before a tuple pattern as in `@‚ü®p1, p2, p3‚ü©` will bind all arguments in the constructor,\n  while leaving the `@` off will only use the patterns on the explicit arguments.\n* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,\n  or a nested disjunction like `a ‚à® b ‚à® c`.\n\nA pattern like `‚ü®a, b, c‚ü© | ‚ü®d, e‚ü©` will do a split over the inductive datatype,\nnaming the first three parameters of the first constructor as `a,b,c` and the\nfirst two of the second constructor `d,e`. If the list is not as long as the\nnumber of arguments to the constructor or the number of constructors, the\nremaining variables will be automatically named. If there are nested brackets\nsuch as `‚ü®‚ü®a‚ü©, b | c‚ü© | d` then these will cause more case splits as necessary.\nIf there are too many arguments, such as `‚ü®a, b, c‚ü©` for splitting on\n`‚àÉ x, ‚àÉ y, p x`, then it will be treated as `‚ü®a, ‚ü®b, c‚ü©‚ü©`, splitting the last\nparameter as necessary.\n\n`rcases` also has special support for quotient types: quotient induction into Prop works like\nmatching on the constructor `quot.mk`.\n\n`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an\nassumption `h : e = PAT` will be added to the context.\n</code>",
 "103": "<code>HilbertCurve.T2_inv_nat (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) : ‚Ñï √ó ‚Ñï</code>",
 "102": "<code>HilbertCurve.T3_inv_nat (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) : ‚Ñï √ó ‚Ñï</code>",
 "101":
 "<code>HMul.hMul.{u, v, w} {Œ± : Type u} {Œ≤ : Type v} {Œ≥ : outParam (Type w)} [self : HMul Œ± Œ≤ Œ≥] : Œ± ‚Üí Œ≤ ‚Üí Œ≥</code><span class=\"sep\"></span><code class=\"docstring\">`a * b` computes the product of `a` and `b`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `*` in identifiers is `mul`.</code>",
 "100": "<code>HilbertCurve.T1_inv_nat (i : ‚Ñï) (mn : ‚Ñï √ó ‚Ñï) : ‚Ñï √ó ‚Ñï</code>",
 "10":
 "<code class=\"docstring\">The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable\n`&gt; 0` for each variable in the sequence. </code>",
 "1": "<code>‚Ñï</code>",
 "0": "<code>hilbert_length (i : ‚Ñï) : ‚Ñï</code>"}